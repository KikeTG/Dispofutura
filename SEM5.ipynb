{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69190f97",
   "metadata": {},
   "source": [
    "<!-- Última modificación: 2024-05-29 14:22:33 -->\n",
    "<!-- Última modificación: 2024-03-22 11:50:24 -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo \"Maestra Aftermarket Actualizable.xlsx\" copiado a la carpeta de la semana actual.\n",
      "La copia del archivo se realizó correctamente.\n",
      "El archivo del OTB Aprobado ya existe en la carpeta de destino: \"C:\\Users\\Etorres\\OneDrive - Inchcape\\Archivo Base Dispo\\Sem 12\\SP Abril 2024-v2.xlsx\"\n",
      "Archivo COD_ACTUAL_S4_20240301.xlsx copiado exitosamente a C:\\Users\\Etorres\\OneDrive - Inchcape\\Archivo Base Dispo\\Sem 12\n",
      "Archivo \"2024-03-18 Stock Tiendas.XLSX\" copiado a la carpeta destino \"C:\\Users\\Etorres\\OneDrive - Inchcape\\Archivo Base Dispo\\Sem 12\".\n",
      "Archivo \"2024-03-18 - Stock S4.xlsx\" copiado a la carpeta destino \"C:\\Users\\Etorres\\OneDrive - Inchcape\\Archivo Base Dispo\\Sem 12\".\n",
      "El archivo \"2024-03-18 TR FINAL S4 Consolidado MT.xlsx\" ya existe en la carpeta destino \"C:\\Users\\Etorres\\OneDrive - Inchcape\\Archivo Base Dispo\\Sem 12\".\n",
      "El archivo 03.2024 S&OP Demanda Sin restricciones Inbound Ciclo Abr 24_Inbound.xlsx ha sido copiado a C:\\Users\\Etorres\\OneDrive - Inchcape\\Archivo Base Dispo\\Sem 12 exitosamente.\n"
     ]
    }
   ],
   "source": [
    "#  COPIAR ARCHIVO BASE SP, MAESTRA AFM, DEFINIR CARPETA DE DESTINO PRINCIPAL, CREAR CARPETA SEMANA ACTUAL, TUBO SEMANAL, STOCK TIENDA, STOCK, TRANSITO CONSOLIDADO\n",
    "# ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import pandas as pd\n",
    "\n",
    "user_home_dir = os.path.expanduser('~')\n",
    "\n",
    "# Obtener el mes actual en formato de nombre (por ejemplo, 'octubre')\n",
    "# Obtener el mes actual y el mes siguiente\n",
    "mes_actual_numero = datetime.now().strftime('%m')\n",
    "mes_siguiente_numero = int(mes_actual_numero) % 12 + 1  # Calcula el mes siguiente\n",
    "mes_actual = datetime.now().strftime('%B').lower()\n",
    "mes_siguiente = calendar.month_name[mes_siguiente_numero].lower()\n",
    "\n",
    "# Mapeo de nombres de meses en inglés a español\n",
    "meses = {\n",
    "    'january': 'enero',\n",
    "    'february': 'febrero',\n",
    "    'march': 'marzo',\n",
    "    'april': 'abril',\n",
    "    'may': 'mayo',\n",
    "    'june': 'junio',\n",
    "    'july': 'julio',\n",
    "    'august': 'agosto',\n",
    "    'september': 'septiembre',\n",
    "    'october': 'octubre',\n",
    "    'november': 'noviembre',\n",
    "    'december': 'diciembre'\n",
    "}\n",
    "\n",
    "# Obtener el nombre del mes en español\n",
    "mes_siguiente = meses.get(mes_siguiente, mes_siguiente)\n",
    "\n",
    "\n",
    "# Ruta de la carpeta donde se encuentran los archivos\n",
    "# carpeta_origen = r'C:\\Users\\Etorres\\Inchcape\\Open to Buy_OTB\\2023 OK'\n",
    "\n",
    "carpeta_origen = os.path.join(user_home_dir, 'Inchcape', 'Planificación y Compras Chile - Documentos', 'Planificación y Compras Aftermarket', 'Open to Buy_OTB', '2024')\n",
    "\n",
    "# RUTA DEL \"C:\\Users\\Etorres\\Inchcape\\Maestros Actualizables\\Maestra Aftermarket Actualizable.xlsx\"\n",
    "# ruta_AFMACTUALIZABLE = r'C:\\Users\\Etorres\\Inchcape\\Maestros Actualizables\\Maestra Aftermarket Actualizable.xlsx'\n",
    "\n",
    "ruta_AFMACTUALIZABLE = os.path.join(user_home_dir, 'Inchcape', 'Planificación y Compras Chile - Documentos', 'Planificación y Compras Maestros', 'Vigencias', 'Maestra Retail', 'Maestra Aftermarket Actualizable.xlsx')\n",
    "\n",
    "\n",
    "# Identificar la subcarpeta que contiene el mes actual en su nombre\n",
    "subcarpetas = [d for d in os.listdir(carpeta_origen) if os.path.isdir(os.path.join(carpeta_origen, d))]\n",
    "subcarpeta_mes = next((d for d in subcarpetas if mes_actual in d.lower()), None)\n",
    "subcarpeta_mes_siguiente = next((d for d in subcarpetas if mes_siguiente in d.lower()), None)\n",
    "\n",
    "if subcarpeta_mes_siguiente:\n",
    "    carpeta_origen_mes_siguiente = os.path.join(carpeta_origen, subcarpeta_mes_siguiente)\n",
    "else:\n",
    "    raise ValueError(f\"No se encontró ninguna subcarpeta que contenga el mes '{mes_siguiente}' en su nombre.\")\n",
    "\n",
    "archivos_otb = [f for f in os.listdir(carpeta_origen_mes_siguiente) \n",
    "                if os.path.isfile(os.path.join(carpeta_origen_mes_siguiente, f)) \n",
    "                and 'SP' in f]\n",
    "\n",
    "if not archivos_otb:\n",
    "    raise ValueError(f\"No se encontraron archivos del OTB Aprobado que contengan 'SP' y '{mes_siguiente}' en su nombre.\")\n",
    "\n",
    "# Seleccionar el archivo más reciente\n",
    "archivo_otb_reciente = max(archivos_otb, key=lambda x: os.path.getmtime(os.path.join(carpeta_origen_mes_siguiente, x)))\n",
    "\n",
    "# Ruta completa del archivo OTB Aprobado más reciente\n",
    "ruta_otb_reciente = os.path.join(carpeta_origen_mes_siguiente, archivo_otb_reciente) \n",
    "\n",
    "\n",
    "# carpeta_destino_principal = r'C:\\Users\\Etorres\\Inchcape\\Archivo Base Dispo'\n",
    "\n",
    "carpeta_destino_principal = os.path.join(user_home_dir, 'OneDrive - Inchcape', 'Archivo Base Dispo')\n",
    "mes_actual = meses.get(mes_actual, mes_actual)\n",
    "\n",
    "\n",
    "# Obtener el número de la semana actual\n",
    "semana_actual = datetime.now().isocalendar()[1]\n",
    "\n",
    "# Ruta de la carpeta de destino con la semana actual\n",
    "carpeta_destino_semana = os.path.join(carpeta_destino_principal, f'Sem {semana_actual}')\n",
    "\n",
    "# Verificar si la carpeta de destino con la semana actual existe o no\n",
    "if not os.path.exists(carpeta_destino_semana):\n",
    "    # Si no existe, crear la carpeta\n",
    "    os.makedirs(carpeta_destino_semana)\n",
    "\n",
    "\n",
    "# Verificar si el archivo \"Maestra Aftermarket Actualizable.xlsx\" existe\n",
    "if os.path.exists(ruta_AFMACTUALIZABLE):\n",
    "    try:\n",
    "        # Copiar el archivo \"Maestra Aftermarket Actualizable.xlsx\" a la carpeta de la semana actual\n",
    "        shutil.copy2(ruta_AFMACTUALIZABLE, carpeta_destino_semana)\n",
    "        print(f'Archivo \"Maestra Aftermarket Actualizable.xlsx\" copiado a la carpeta de la semana actual.')\n",
    "        \n",
    "        # Verificar si la copia fue exitosa\n",
    "        archivo_copiado = os.path.join(carpeta_destino_semana, os.path.basename(ruta_AFMACTUALIZABLE))\n",
    "        if os.path.exists(archivo_copiado):\n",
    "            print(\"La copia del archivo se realizó correctamente.\")\n",
    "        else:\n",
    "            print(\"No se encontró el archivo copiado en la carpeta de destino.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error al copiar el archivo: {e}\")\n",
    "else:\n",
    "    print(f'El archivo \"{ruta_AFMACTUALIZABLE}\" no existe o no se encuentra en la ruta especificada.')\n",
    "\n",
    "\n",
    "ruta_destino_otb = os.path.join(carpeta_destino_semana, archivo_otb_reciente)\n",
    "if os.path.exists(ruta_destino_otb):\n",
    "    print(f'El archivo del OTB Aprobado ya existe en la carpeta de destino: \"{ruta_destino_otb}\"')\n",
    "else:\n",
    "    # Copiar el archivo del OTB Aprobado a la carpeta de destino\n",
    "    shutil.copy2(ruta_otb_reciente, carpeta_destino_semana)\n",
    "    print(f'Archivo del OTB Aprobado copiado a la carpeta de destino.')\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Obtener el primer día del mes actual\n",
    "primer_dia_mes_actual = datetime.now().replace(day=1)\n",
    "\n",
    "# Restar un día para obtener el último día del mes anterior\n",
    "ultimo_dia_mes_anterior = primer_dia_mes_actual - timedelta(days=1)\n",
    "\n",
    "# Extraer el mes anterior\n",
    "mes_anterior_numero = ultimo_dia_mes_anterior.strftime('%m')\n",
    "\n",
    "# cod actual s4 mes anterior\n",
    "# ruta_base = \"C:\\\\Users\\\\Etorres\\\\Inchcape\\\\Planificación y Compras Maestros\\\\2023\\\\\"\n",
    "ruta_base = os.path.join(user_home_dir, \"Inchcape\", \"Planificación y Compras Chile - Documentos\", \"Planificación y Compras Maestros\", \"2024\")\n",
    "\n",
    "nombre_carpeta = f\"2024-{mes_anterior_numero}\"\n",
    "ruta_carpeta_mes = os.path.join(ruta_base, nombre_carpeta)\n",
    "# Obtener el año actual en formato de cadena\n",
    "anioo_actual = datetime.now().strftime('%Y')\n",
    "\n",
    "# Crear la ruta de la carpeta del mes actual\n",
    "nombre_carpeta_actual = f\"{anioo_actual}-{mes_actual_numero}\"\n",
    "ruta_carpeta_mes_actual = os.path.join(ruta_base, nombre_carpeta_actual)\n",
    "\n",
    "archivo_encontrado = None\n",
    "for archivo in os.listdir(ruta_carpeta_mes_actual):\n",
    "    if archivo.startswith(\"COD_ACTUAL_S4\"):\n",
    "        archivo_encontrado = archivo\n",
    "        break\n",
    "\n",
    "if archivo_encontrado:\n",
    "    ruta_origen = os.path.join(ruta_carpeta_mes_actual, archivo_encontrado)\n",
    "    shutil.copy(ruta_origen, carpeta_destino_semana)\n",
    "    print(f\"Archivo {archivo_encontrado} copiado exitosamente a {carpeta_destino_semana}\")\n",
    "else:\n",
    "    print(\"No se encontró el archivo que comienza con 'COD_ACTUAL_S4'\")\n",
    "def es_formato_fecha_valido(nombre_carpeta):\n",
    "    try:\n",
    "        datetime.strptime(nombre_carpeta, \"%Y-%m-%d\")\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "# Ruta donde están las carpetas con fechas\n",
    "# ruta_kpi_reportes = r'C:\\Users\\Etorres\\Inchcape\\Planificación y Compras KPI-Reportes\\Tubo Semanal'\n",
    "\n",
    "ruta_kpi_reportes = os.path.join(user_home_dir, 'Inchcape', 'Planificación y Compras Chile - Documentos','Planificación y Compras KPI-Reportes', 'Tubo Semanal')\n",
    "\n",
    "# Obtener una lista de todas las carpetas en la ruta_kpi_reportes que cumplan con el formato de fecha\n",
    "carpetas = [d for d in os.listdir(ruta_kpi_reportes) if os.path.isdir(os.path.join(ruta_kpi_reportes, d)) and es_formato_fecha_valido(d)]\n",
    "\n",
    "# Ordenar las carpetas por su fecha\n",
    "carpetas_ordenadas = sorted(carpetas, key=lambda x: datetime.strptime(x, \"%Y-%m-%d\"), reverse=True)\n",
    "\n",
    "# Tomar la carpeta más cercana a la fecha actual (la primera en la lista ordenada)\n",
    "carpeta_mas_cercana = carpetas_ordenadas[0]\n",
    "\n",
    "# Ruta completa de la carpeta seleccionada\n",
    "ruta_carpeta_seleccionada = os.path.join(ruta_kpi_reportes, carpeta_mas_cercana)\n",
    "\n",
    "# Buscar el archivo que contiene \"Stock Tiendas\" en su nombre\n",
    "archivo_stock_tiendas = next((f for f in os.listdir(ruta_carpeta_seleccionada) if \"Stock Tiendas\" in f and \"Tiendas\" in f), None)\n",
    "\n",
    "# Si encontramos el archivo, copiamos a la carpeta_destino_semana\n",
    "if archivo_stock_tiendas:\n",
    "    ruta_origen_stock = os.path.join(ruta_carpeta_seleccionada, archivo_stock_tiendas)\n",
    "    shutil.copy2(ruta_origen_stock, carpeta_destino_semana)\n",
    "    print(f'Archivo \"{archivo_stock_tiendas}\" copiado a la carpeta destino \"{carpeta_destino_semana}\".')\n",
    "else:\n",
    "    print(f\"No se encontró ningún archivo con 'StockTIENDAS' en su nombre en la carpeta {carpeta_mas_cercana}.\")\n",
    "ruta_destino_stock = os.path.join(carpeta_destino_semana,archivo_stock_tiendas)\n",
    "archivo_stock_tiendas2 = next((f for f in os.listdir(ruta_carpeta_seleccionada) if \"Stock S4\" in f and not ('Tiendas' in f or 'Pa' in f or 'Centro' in f or 'R3' in f)), None)\n",
    "\n",
    "#     # Si encontramos el archivo, copiamos a la carpeta_destino_semana\n",
    "if archivo_stock_tiendas2:\n",
    "    ruta_origen_stock2 = os.path.join(ruta_carpeta_seleccionada, archivo_stock_tiendas2)\n",
    "    shutil.copy2(ruta_origen_stock2, carpeta_destino_semana)\n",
    "    print(f'Archivo \"{archivo_stock_tiendas2}\" copiado a la carpeta destino \"{carpeta_destino_semana}\".')\n",
    "else:\n",
    "    print(f\"No se encontró ningún archivo con 'Stock S4' en su nombre en la carpeta {carpeta_mas_cercana}.\")\n",
    "\n",
    "ruta_destino_stock2 = os.path.join(carpeta_destino_semana, archivo_stock_tiendas2)\n",
    "archivo_stock_tiendas3 = next((f for f in os.listdir(ruta_carpeta_seleccionada) if \"onsolidado\" in f and 'S4' in f), None)\n",
    "\n",
    "if archivo_stock_tiendas3:\n",
    "    ruta_destino_stock3 = os.path.join(carpeta_destino_semana, archivo_stock_tiendas3)\n",
    "    ruta_origen_stock3 = os.path.join(ruta_carpeta_seleccionada, archivo_stock_tiendas3)\n",
    "    # Verificar si el archivo ya existe en la carpeta de destino\n",
    "    if not os.path.exists(ruta_destino_stock3):\n",
    "        shutil.copy2(ruta_origen_stock3, carpeta_destino_semana)\n",
    "        print(f'Archivo \"{archivo_stock_tiendas3}\" (CONSOLIDADO) copiado a la carpeta destino \"{carpeta_destino_semana}\".')\n",
    "    else:\n",
    "        print(f'El archivo \"{archivo_stock_tiendas3}\" ya existe en la carpeta destino \"{carpeta_destino_semana}\".')\n",
    "else:\n",
    "    print(f\"No se encontró ningún archivo con 'Stock CONSOLIDADO' en su nombre en la carpeta {ruta_carpeta_seleccionada}.\")\n",
    "#BUSCAR FORECAST ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "import locale\n",
    "\n",
    "# Ruta donde se encuentran las carpetas por año y mes\n",
    "# directorio_forecast = r\"C:\\Users\\Etorres\\Inchcape\\Forecast Inbound\"\n",
    "\n",
    "directorio_forecast = os.path.join(user_home_dir, 'Inchcape', 'Planificación y Compras Chile - Documentos', 'Planificación y Compras Aftermarket', 'Forecast Inbound')\n",
    "\n",
    "\n",
    "# Mapeo de nombres de meses en inglés a español\n",
    "meses_en_espanol = {\n",
    "    \"January\": \"Enero\",\n",
    "    \"February\": \"Febrero\",\n",
    "    \"March\": \"Marzo\",\n",
    "    \"April\": \"Abril\",\n",
    "    \"May\": \"Mayo\",\n",
    "    \"June\": \"Junio\",\n",
    "    \"July\": \"Julio\",\n",
    "    \"August\": \"Agosto\",\n",
    "    \"September\": \"Septiembre\",\n",
    "    \"October\": \"Octubre\",\n",
    "    \"November\": \"Noviembre\",\n",
    "    \"December\": \"Diciembre\"\n",
    "}\n",
    "\n",
    "# Establece el entorno local a inglés para obtener el mes en inglés\n",
    "locale.setlocale(locale.LC_TIME, 'en_US.UTF-8')\n",
    "\n",
    "# Función para obtener el nombre de la carpeta objetivo\n",
    "def obtener_nombre_carpeta(fecha):\n",
    "    año = fecha.strftime(\"%Y\")\n",
    "    mes_inglés = fecha.strftime(\"%B\")\n",
    "    mes_español = meses_en_espanol[mes_inglés]\n",
    "    mes_número = fecha.strftime(\"%m\")\n",
    "    return f\"{año}-{mes_número} {mes_español}\"\n",
    "\n",
    "fecha_actual = datetime.now()\n",
    "# No necesitas restarle días, ya que deseas el mes actual\n",
    "nombre_carpeta_mes_actual = obtener_nombre_carpeta(fecha_actual)\n",
    "\n",
    "# Buscar la carpeta del mes actual\n",
    "ruta_carpeta_encontrada = \"\"\n",
    "for nombre_carpeta in os.listdir(directorio_forecast):\n",
    "    if nombre_carpeta_mes_actual in nombre_carpeta:\n",
    "        ruta_carpeta_encontrada = os.path.join(directorio_forecast, nombre_carpeta)\n",
    "        break\n",
    "\n",
    "# Si se encontró la carpeta del mes anterior\n",
    "if ruta_carpeta_encontrada:\n",
    "    # Buscar el archivo con la palabra \"Inbound\" más reciente\n",
    "    lista_archivos = [archivo for archivo in os.listdir(ruta_carpeta_encontrada) if \"Inbound\" in archivo]\n",
    "    lista_archivos.sort(key=lambda archivo: os.path.getmtime(os.path.join(ruta_carpeta_encontrada, archivo)), reverse=True)\n",
    "    \n",
    "    if lista_archivos:\n",
    "        archivo_reciente = lista_archivos[0]\n",
    "        ruta_completa_archivo = os.path.join(ruta_carpeta_encontrada, archivo_reciente)\n",
    "        \n",
    "        # Copiar el archivo más reciente a la carpeta destino\n",
    "        shutil.copy(ruta_completa_archivo, carpeta_destino_semana)\n",
    "        print(f\"El archivo {archivo_reciente} ha sido copiado a {carpeta_destino_semana} exitosamente.\")\n",
    "    else:\n",
    "        print(f\"No se encontraron archivos con la palabra 'Inbound' en {ruta_carpeta_encontrada}.\")\n",
    "else:\n",
    "    print(f\"No se encontró la carpeta para el mes anterior.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#COPIAR Y PEGAR LO DEL SP Y CALCULAR LEADTIME SEMANAL  ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "df = pd.read_excel(ruta_destino_otb, sheet_name=\"Base\", usecols=\"A:B, D:I, K:L, N, CX, CY, ER, EU, M, ET, DM:DN\", skiprows=1)\n",
    "\n",
    "df.insert(11, 'Leadtime Semanal', (df.iloc[:, 10] / 7).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD ACTUAL</th>\n",
       "      <th>vig may</th>\n",
       "      <th>vig gt</th>\n",
       "      <th>vig retail</th>\n",
       "      <th>vig total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000078</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  COD ACTUAL  vig may  vig gt  vig retail  vig total\n",
       "0    1000078        0       0           0          0\n",
       "1    1000143        0       0           0          0\n",
       "2    1000144        0       0           0          0\n",
       "3    1000147        0       0           1          1\n",
       "4    1000148        0       0           1          1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CALCULO VIGENCIA ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "nombres_columnas = [\"Material SAP\", \"Condicion de Compra\", \"CES 01\", \"Mayorista\", \"Sodimac\", \"Easy\", \"Walmart\", \"SMU\", \"Tottus\", \"Retail (AP-AG)\"]\n",
    "ruta_archivo_2 = os.path.join(carpeta_destino_semana, \"Maestra Aftermarket Actualizable.xlsx\")\n",
    "dataframe_maestra_2 = pd.read_excel(ruta_archivo_2, usecols=nombres_columnas)#, skiprows=1)\n",
    "\n",
    "agrupado_2 = dataframe_maestra_2.groupby(by=[\"Material SAP\", \"Condicion de Compra\"]).sum().reset_index()\n",
    "\n",
    "dataframe_maestra_2['vig may'] = ((dataframe_maestra_2['CES 01'] + dataframe_maestra_2['Mayorista']) != 0).astype(int)\n",
    "\n",
    "dataframe_maestra_2['vig gt'] = ((dataframe_maestra_2[['Sodimac', 'Easy', 'Walmart', 'SMU', 'Tottus']].sum(axis=1)) != 0).astype(int)\n",
    "\n",
    "cond1 = dataframe_maestra_2['Retail (AP-AG)'] != 0\n",
    "cond2 = dataframe_maestra_2['Condicion de Compra'] != 2\n",
    "dataframe_maestra_2['vig retail'] = (cond1 & cond2).astype(int)\n",
    "\n",
    "dataframe_maestra_2['vig total'] = ((dataframe_maestra_2[['vig may', 'vig gt', 'vig retail']].sum(axis=1)) != 0).astype(int)\n",
    "\n",
    "#LEER CODIGO S4 MES ANTERIOR ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# 1. Buscar el archivo que comienza con 'COD_ACTUAL_S4' en la carpeta destino\n",
    "archivo_cod_actual = None\n",
    "for archivo in os.listdir(carpeta_destino_semana):\n",
    "    if archivo.startswith(\"COD_ACTUAL_S4\"):\n",
    "        archivo_cod_actual = archivo\n",
    "        break\n",
    "\n",
    "# 2. Leer las columnas requeridas del archivo encontrado\n",
    "ruta_archivo_cod_actual = os.path.join(carpeta_destino_semana, archivo_cod_actual)\n",
    "df_cod_actual = pd.read_excel(ruta_archivo_cod_actual, usecols=[\"Nro_pieza_fabricante_1\", \"Cod_Actual_1\"])\n",
    "\n",
    "# Convertir las columnas a strings para asegurarse de que tengan el mismo tipo de datos\n",
    "dataframe_maestra_2['Material SAP'] = dataframe_maestra_2['Material SAP'].astype(str)\n",
    "df_cod_actual['Nro_pieza_fabricante_1'] = df_cod_actual['Nro_pieza_fabricante_1'].astype(str)\n",
    "\n",
    "# 3. Realizar merge\n",
    "dataframe_maestra_2 = dataframe_maestra_2.merge(df_cod_actual, left_on='Material SAP', right_on='Nro_pieza_fabricante_1', how='left')\n",
    "\n",
    "# 4. Si no hay coincidencia en el cruce, llenar \"Cod_Actual_1\" con el valor de \"Material SAP\"\n",
    "dataframe_maestra_2[\"Cod_Actual_1\"].fillna(dataframe_maestra_2[\"Material SAP\"], inplace=True)\n",
    "\n",
    "# 5. Renombrar la columna y eliminar la columna adicional\n",
    "dataframe_maestra_2.rename(columns={\"Cod_Actual_1\": \"COD ACTUAL\"}, inplace=True)\n",
    "dataframe_maestra_2.drop(columns='Nro_pieza_fabricante_1', inplace=True)\n",
    "\n",
    "# groupby\n",
    "df_agrupado = dataframe_maestra_2.groupby('COD ACTUAL').agg({\n",
    "    'vig may': 'sum',\n",
    "    'vig gt': 'sum',\n",
    "    'vig retail': 'sum',\n",
    "    'vig total': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Reemplazar valores mayores a 1 por 1\n",
    "cols = ['vig may', 'vig gt', 'vig retail', 'vig total']\n",
    "for col in cols:\n",
    "    df_agrupado[col] = df_agrupado[col].apply(lambda x: 1 if x > 1 else x)\n",
    "\n",
    "df_agrupado.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Falt & Sobr AP Y AGP_18.03.24.xlsx copiado exitosamente a C:\\Users\\Etorres\\OneDrive - Inchcape\\Archivo Base Dispo\\Sem 12\n",
      "       Ultimo Slabon  Faltante  Sobrante\n",
      "0             100483        18       0.0\n",
      "1             100484         1       0.0\n",
      "2             100485        15       0.0\n",
      "3             100486        42     124.0\n",
      "4             100487        52       3.0\n",
      "...              ...       ...       ...\n",
      "10793        1167589        32       0.0\n",
      "10794        1167590        37       0.0\n",
      "10795        1167591        20       0.0\n",
      "10796        1167595        11       0.0\n",
      "10797        1169506        41       0.0\n",
      "\n",
      "[10798 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convertir las columnas 'Material' y 'COD ACTUAL' a tipo object\n",
    "df['Material'] = df['Material'].astype(str)\n",
    "df_agrupado['COD ACTUAL'] = df_agrupado['COD ACTUAL'].astype(str)\n",
    "\n",
    "# Hacer el merge, solo con las columnas especificadas\n",
    "df_resultado = df.merge(df_agrupado[['COD ACTUAL', 'vig may', 'vig gt', 'vig retail']],\n",
    "                        left_on='Material', \n",
    "                        right_on='COD ACTUAL', \n",
    "                        how='left')\n",
    "\n",
    "# Rellenar con 0 en caso de que no haya coincidencias\n",
    "for columna in ['vig may', 'vig gt', 'vig retail']:\n",
    "    df_resultado[columna].fillna(0, inplace=True)\n",
    "\n",
    "# Eliminar la columna 'COD ACTUAL'\n",
    "df_resultado = df_resultado.drop('COD ACTUAL', axis=1)\n",
    "\n",
    "# Crear la columna 'Vigencia Total'\n",
    "df_resultado['Vigencia Total'] = df_resultado[['vig may', 'vig gt', 'vig retail']].sum(axis=1).apply(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "# Reemplazar df con el dataframe resultante\n",
    "df = df_resultado\n",
    "\n",
    "# OBSOLECENCIA ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# Obtener la lista de columnas del dataframe\n",
    "columnas = df_resultado.columns.tolist()\n",
    "\n",
    "# Remover 'OBS Retail' y 'OBS DERCO' de la lista\n",
    "columnas.remove('OBS Retail')\n",
    "columnas.remove('OBS DERCO')\n",
    "\n",
    "# Ajustar los valores negativos a 0 en 'OBS Retail' y 'OBS DERCO'\n",
    "df_resultado['OBS Retail'] = df_resultado['OBS Retail'].apply(lambda x: 0 if x < 0 else x)\n",
    "df_resultado['OBS DERCO'] = df_resultado['OBS DERCO'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "# Agregar 'OBS Retail' y 'OBS DERCO' al final de la lista\n",
    "columnas.extend(['OBS Retail', 'OBS DERCO'])\n",
    "\n",
    "# Reorganizar las columnas \n",
    "df_resultado = df_resultado[columnas]\n",
    "\n",
    "df_resultado = df_resultado.copy()\n",
    "\n",
    "# Crear la columna 'Obs Total' utilizando .loc\n",
    "df_resultado.loc[:, 'Obs Total'] = (df_resultado['OBS Retail'] + df_resultado['OBS DERCO'] > 0).astype(int)\n",
    "\n",
    "# Agregar 'Obs Total' al final de la lista de columnas\n",
    "columnas.append('Obs Total')\n",
    "\n",
    "# Reorganizar las columnas del dataframe para asegurarse de que 'Obs Total' esté al final\n",
    "df_resultado = df_resultado[columnas]\n",
    "#FALTANTES Y SOBRANTES ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Ruta de origen\n",
    "# ruta_origen = r\"C:\\Users\\Etorres\\Inchcape\\Planificación y Compras KPI-Reportes\\Faltantes y Sobrantes Retail\\Consolidado Sobrantes y Faltantes AP - AGP\"\n",
    "\n",
    "ruta_origen = os.path.join(user_home_dir, 'Inchcape', 'Planificación y Compras Chile - Documentos', 'Planificación y Compras KPI-Reportes', 'Faltantes y Sobrantes Retail', 'Sobrantes y Faltantes AP - AGP')\n",
    "\n",
    "# Lista todos los archivos en la ruta de origen\n",
    "archivos = [f for f in os.listdir(ruta_origen) if os.path.isfile(os.path.join(ruta_origen, f))]\n",
    "\n",
    "# Función para extraer la fecha del nombre del archivo\n",
    "def extraer_fecha(archivo):\n",
    "    # Intenta el primer patrón\n",
    "    match = re.search(r\"(\\d{2}.\\d{2}.\\d{4})\", archivo)\n",
    "    if match:\n",
    "        fecha_str = match.group(1)\n",
    "        return datetime.strptime(fecha_str, \"%d.%m.%Y\")\n",
    "    # Si el primer patrón no funciona, intenta el segundo\n",
    "    match = re.search(r\"(\\d{2}.\\d{2}.\\d{2})\", archivo)\n",
    "    if match:\n",
    "        fecha_str = match.group(1)\n",
    "        return datetime.strptime(fecha_str, \"%d.%m.%y\")\n",
    "    return None\n",
    "\n",
    "# Obtener el mes y año actual\n",
    "mes_actual = datetime.now().month\n",
    "año_actual = datetime.now().year\n",
    "\n",
    "# Si estamos en enero, el mes anterior sería diciembre del año pasado\n",
    "if mes_actual == 1:\n",
    "    mes_anterior = 12\n",
    "    año_anterior = año_actual - 1\n",
    "else:\n",
    "    mes_anterior = mes_actual - 1\n",
    "    año_anterior = año_actual\n",
    "\n",
    "# Filtra solo los archivos que contienen una fecha en su nombre son excel y del mes pasado\n",
    "# archivos_filtrados = [\n",
    "#     f for f in archivos if extraer_fecha(f) \n",
    "#     and extraer_fecha(f).month == mes_anterior \n",
    "#     and extraer_fecha(f).year == año_anterior \n",
    "#     and (f.endswith('.xlsx') or f.endswith('.xls')) \n",
    "#     and \"xD\".lower() not in f.lower()\n",
    "# ]\n",
    "# Filtra solo los archivos que contienen una fecha en su nombre son excel y mes actual\n",
    "archivos_filtrados = [\n",
    "    f for f in archivos if extraer_fecha(f) \n",
    "    and extraer_fecha(f).month == mes_actual   # Cambiado a mes_actual\n",
    "    and extraer_fecha(f).year == año_actual    # Cambiado a año_actual\n",
    "    and (f.endswith('.xlsx') or f.endswith('.xls')) \n",
    "    and \"xD\".lower() not in f.lower()\n",
    "]\n",
    "\n",
    "# Si no hay archivos que cumplan el criterio\n",
    "if not archivos_filtrados:\n",
    "    print(\"No se encontró un archivo que cumpla con los criterios.\")\n",
    "    exit()\n",
    "\n",
    "# Ordena los archivos por fecha\n",
    "archivos_filtrados.sort(key=extraer_fecha, reverse=True)\n",
    "\n",
    "# Toma el archivo con la fecha más cercana al mes actual (o el único archivo si solo hay uno)\n",
    "archivo_a_mover = archivos_filtrados[0]\n",
    "\n",
    "try:\n",
    "    shutil.copy(os.path.join(ruta_origen, archivo_a_mover), carpeta_destino_semana)\n",
    "    print(f\"Archivo {archivo_a_mover} copiado exitosamente a {carpeta_destino_semana}\")\n",
    "except shutil.Error as e:\n",
    "    print(f\"Error al copiar el archivo: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inesperado: {e}\")\n",
    "\n",
    "\n",
    "# Define la ruta completa de destino\n",
    "ruta_destino_completa = os.path.join(carpeta_destino_semana, archivo_a_mover)\n",
    "# ruta_destino_completa = r'C:\\Users\\Etorres\\Inchcape\\Archivo Base Dispo\\Sem 47\\Falt & Sobr AP Y AGP_06.11.23 (Mat-Cen).XLSX'\n",
    "# ruta_destino_completa = os.path.join(user_home_dir, 'Inchcape', 'Archivo Base Dispo', 'Sem 47', 'Falt & Sobr AP Y AGP_06.11.23 (Mat-Cen).XLSX')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Función auxiliar para buscar una hoja que contenga 'TB' en su nombre\n",
    "def encontrar_hoja_tb(ruta_destino_completa):\n",
    "    xl = pd.ExcelFile(ruta_destino_completa)\n",
    "    for sheet_name in xl.sheet_names:\n",
    "        if 'TB' in sheet_name:\n",
    "            return sheet_name\n",
    "    return None  # Retornar None si no se encuentra ninguna hoja\n",
    "\n",
    "# Cargar la hoja correcta\n",
    "hoja_tb = encontrar_hoja_tb(ruta_destino_completa)\n",
    "if hoja_tb is None:\n",
    "    print(\"No se encontró una hoja que contenga 'TB' en su nombre.\")\n",
    "    exit()\n",
    "\n",
    "# Cargar solo las primeras 5 columnas\n",
    "df = pd.read_excel(ruta_destino_completa, sheet_name=hoja_tb, usecols=range(5))\n",
    "\n",
    "# Preprocesamiento para manejar variaciones en los nombres de las columnas\n",
    "# Crear un mapeo de nombres esperados a posibles variaciones\n",
    "column_mapping = {\n",
    "    'POG': ['POG'],\n",
    "    'Ultimo Slabon': ['Ultimo Slabon', 'Ultmo Slabon', 'Slabon', 'Último Eslabón'],\n",
    "    'Faltante': ['Faltante', 'Faltantes', 'Faltante '],\n",
    "    'Sobrante': ['Sobrante', 'Sobrantes', 'Sobrante '],\n",
    "    'Stock Objetivo': ['Stock Objetivo', 'Stock Objetivo ']\n",
    "}\n",
    "\n",
    "# Normalizar los nombres de las columnas\n",
    "for expected, variations in column_mapping.items():\n",
    "    for variation in variations:\n",
    "        if variation in df.columns:\n",
    "            df.rename(columns={variation: expected}, inplace=True)\n",
    "\n",
    "# Filtrar por POG = 'AP' y luego realizar el groupby por 'Ultimo Slabon'\n",
    "# Sumar las columnas 'Faltante' y 'Sobrante'\n",
    "Resumen_AP = df[df['POG'] == 'AP'].groupby('Ultimo Slabon')[['Faltante', 'Sobrante']].sum().reset_index()\n",
    "\n",
    "# Mostrar el DataFrame 'Resumen AP'\n",
    "print(Resumen_AP)\n",
    "Resumen_AGP = df[df['POG'] == 'AGP'].groupby('Ultimo Slabon')[['Faltante', 'Sobrante']].sum().reset_index()\n",
    "\n",
    "\n",
    "df_resultado['Material'] = df_resultado['Material'].astype(str).str.strip().str.lower()\n",
    "Resumen_AP[Resumen_AP.columns[0]] = Resumen_AP[Resumen_AP.columns[0]].astype(str).str.strip().str.lower()\n",
    "Resumen_AGP[Resumen_AGP.columns[0]] = Resumen_AGP[Resumen_AGP.columns[0]].astype(str).str.strip().str.lower()\n",
    "\n",
    "merged_df = pd.merge(df_resultado, Resumen_AP, left_on='Material', right_on=Resumen_AP.columns[0], how='left')\n",
    "merged_df.drop(Resumen_AP.columns[0], axis=1, inplace=True)\n",
    "merged_df.rename(columns={'Faltante': 'Faltante AP', 'Sobrante': 'Sobrante AP'}, inplace=True)\n",
    "# Reemplazando NaN por 0\n",
    "merged_df['Faltante AP'] = merged_df['Faltante AP'].fillna(0)\n",
    "merged_df['Sobrante AP'] = merged_df['Sobrante AP'].fillna(0)\n",
    "\n",
    "# Segundo merge: Uniendo merged_df con Resumen_AGP\n",
    "merged_df2 = pd.merge(merged_df, Resumen_AGP, left_on='Material', right_on=Resumen_AGP.columns[0], how='left')\n",
    "merged_df2.drop(Resumen_AGP.columns[0], axis=1, inplace=True)\n",
    "merged_df2.rename(columns={'Faltante': 'Faltante AGP', 'Sobrante': 'Sobrante AGP'}, inplace=True)\n",
    "# Reemplazando NaN por 0\n",
    "merged_df2['Faltante AGP'] = merged_df2['Faltante AGP'].fillna(0)\n",
    "merged_df2['Sobrante AGP'] = merged_df2['Sobrante AGP'].fillna(0)\n",
    "\n",
    "\n",
    "merged_df2['Faltantes'] = merged_df2['Faltante AP'] + merged_df2['Faltante AGP']\n",
    "merged_df2['Sobrantes'] = merged_df2['Sobrante AP'] + merged_df2['Sobrante AGP']\n",
    "\n",
    "columnas_existentes = [col for col in merged_df2.columns if col not in ['Material', 'Faltante AP', 'Faltante AGP', 'Sobrante AP', 'Sobrante AGP', 'Faltantes', 'Sobrantes']]\n",
    "column_order = ['Material'] + columnas_existentes + ['Faltante AP', 'Faltante AGP', 'Faltantes', 'Sobrante AP', 'Sobrante AGP', 'Sobrantes']\n",
    "\n",
    "\n",
    "merged_df2 = merged_df2[column_order]\n",
    "\n",
    "#PLANOGRAMA ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "\n",
    "# Obteniendo la primera columna de Resumen_AP y Resumen_AGP\n",
    "primer_columna_AP = Resumen_AP.columns[0]\n",
    "primer_columna_AGP = Resumen_AGP.columns[0]\n",
    "\n",
    "# Creando la columna 'AP' en Merged_df2\n",
    "merged_df2['AP'] = merged_df2['Material'].isin(Resumen_AP[primer_columna_AP]).astype(int)\n",
    "\n",
    "# Creando la columna 'AGP' en Merged_df2\n",
    "merged_df2['AGP'] = merged_df2['Material'].isin(Resumen_AGP[primer_columna_AGP]).astype(int)\n",
    "merged_df2['Total Planograma'] = ((merged_df2['AGP'] + merged_df2['AP']) != 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRUCE STOCK TIENDAS ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el DataFrame desde el archivo Excel\n",
    "df123 = pd.read_excel(ruta_destino_stock, sheet_name=\"Sheet1\", usecols=['Material', 'Libre utilización', 'Almacén'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Hay duplicados?: False\n",
      "Número de duplicados: 0\n",
      "Empty DataFrame\n",
      "Columns: [Material, Libre utilización]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convertir 'Material' a entero (si es posible), luego a cadena para eliminar '.0'\n",
    "df123['Material'] = pd.to_numeric(df123['Material'], errors='coerce').fillna(0).astype(int).astype(str)\n",
    "\n",
    "# Convertir 'Libre utilización' y 'Almacén' a numérico\n",
    "df123['Libre utilización'] = pd.to_numeric(df123['Libre utilización'], errors='coerce')\n",
    "df123['Almacén'] = pd.to_numeric(df123['Almacén'], errors='coerce')\n",
    "\n",
    "# Filtrar por 'Almacén' para quedarse con 1100.0 y NaN\n",
    "# filtered_df = df123[(df123['Almacén'] == 1100.0) | (df123['Almacén'].isna())]\n",
    "filtered_df = df123\n",
    "\n",
    "# Realizar el cruce (merge) entre los DataFrames\n",
    "TiendaUE = pd.merge(filtered_df, df_cod_actual, left_on='Material', right_on='Nro_pieza_fabricante_1', how='left')\n",
    "\n",
    "# Rellenar los NaN en 'Cod_Actual_1' con los valores de 'Material' original\n",
    "TiendaUE['Cod_Actual_1'] = TiendaUE['Cod_Actual_1'].fillna(TiendaUE['Material'])\n",
    "\n",
    "# Eliminar la columna 'Material' y renombrar 'Cod_Actual_1' a 'Material'\n",
    "TiendaUE = TiendaUE.drop('Material', axis=1)\n",
    "TiendaUE.rename(columns={'Cod_Actual_1': 'Material'}, inplace=True)\n",
    "\n",
    "# Aquí se ajustan los valores de 'Libre utilización' menores a 0 a 0\n",
    "TiendaUE['Libre utilización'] = TiendaUE['Libre utilización'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "# Agrupar por 'Material' y sumar 'Libre utilización'\n",
    "df_stock = TiendaUE.groupby('Material')['Libre utilización'].sum().reset_index()\n",
    "\n",
    "# Ajustar valores menores a 1 a 0\n",
    "df_stock['Libre utilización'] = df_stock['Libre utilización'].apply(lambda x: 0 if x < 1 else x)\n",
    "\n",
    "# Convertir 'Libre utilización' a entero para eliminar decimales no necesarios\n",
    "df_stock['Libre utilización'] = df_stock['Libre utilización'].astype(int)\n",
    "\n",
    "duplicados = df_stock['Material'].duplicated()\n",
    "\n",
    "# Para ver si hay al menos un duplicado en esa columna\n",
    "hay_duplicados = duplicados.any()\n",
    "print(\"¿Hay duplicados?:\", hay_duplicados)\n",
    "\n",
    "# Para contar el número total de duplicados en esa columna\n",
    "numero_duplicados = duplicados.sum()\n",
    "print(\"Número de duplicados:\", numero_duplicados)\n",
    "\n",
    "# Para obtener un DataFrame con todos los duplicados en esa columna\n",
    "df_duplicados = df_stock[df_stock['Material'].duplicated(keep=False)]\n",
    "print(df_duplicados)\n",
    "\n",
    "df_stock.rename(columns={'Libre utilización': 'Stock Tiendas'}, inplace=True)\n",
    "df_stock['Material'] = df_stock['Material'].fillna(0).astype(int)\n",
    "df_stock['Stock Tiendas'] = df_stock['Stock Tiendas'].fillna(0).astype(int)\n",
    "\n",
    "#STOCK CD ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Especifica las columnas que necesitas\n",
    "# cols_to_use3 = ['Material', 'Libre utilización', 'Alm.', 'Ce.', 'Insp. Calidad', 'Traslado', 'Ult. Eslabon']\n",
    "cols_to_use3 = ['Ult. Eslabon', 'Libre utilización', 'Almacén', 'Centro', 'Inspecc.de calidad', 'Trans./Trasl.']\n",
    "# Convertir la columna 'Material' a tipo object (string) para evitar el .0\n",
    "# df_filtered1.rename(columns={'Inspecc.de calidad': 'Material'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVISAR EL MATERIAL STR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convertir las columnas 'Material' y 'COD ACTUAL' a tipo object\n",
    "if 'Material' in df.columns:\n",
    "    df['Material'] = df['Material'].astype(str)\n",
    "# Si la columna 'Material' no está, buscar 'Ultimo Slabon'\n",
    "elif 'Ultimo Slabon' in df.columns:\n",
    "    df['Ultimo Slabon'] = df['Ultimo Slabon'].astype(str)\n",
    "# Si ninguna de las dos columnas está presente, no hacer nada\n",
    "else:\n",
    "    pass\n",
    "df_agrupado['COD ACTUAL'] = df_agrupado['COD ACTUAL'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carga solo las columnas que necesitas desde la hoja \"Sheet1\"\n",
    "dfleerstock = pd.read_excel(ruta_destino_stock2, sheet_name='Sheet1', usecols=cols_to_use3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Centro</th>\n",
       "      <th>Almacén</th>\n",
       "      <th>Libre utilización</th>\n",
       "      <th>Trans./Trasl.</th>\n",
       "      <th>Inspecc.de calidad</th>\n",
       "      <th>Ult. Eslabon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>714</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>714</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>714</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>714</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Centro  Almacén  Libre utilización  Trans./Trasl.  Inspecc.de calidad  \\\n",
       "0     714   1100.0                1.0              0                   0   \n",
       "1     714   1100.0                2.0              0                   0   \n",
       "2     714   1100.0                3.0              0                   0   \n",
       "3     714   1100.0                3.0              0                   0   \n",
       "4     714   1100.0                1.0              0                   0   \n",
       "\n",
       "  Ult. Eslabon  \n",
       "0       100483  \n",
       "1       100495  \n",
       "2       100498  \n",
       "3       100499  \n",
       "4       100505  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfleerstock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en Alm.: ['1100' '0' '1600']\n",
      "Valores únicos en Ce.: ['714' '711' '710' '496' '712']\n",
      "¿Hay duplicados?: False\n",
      "Número de duplicados: 0\n",
      "Empty DataFrame\n",
      "Columns: [Material, Libre utilización, Insp. Calidad, Traslado, Control]\n",
      "Index: []\n",
      "¿Hay duplicados?: True\n",
      "Número de duplicados: 2796\n",
      "      Centro Almacén  Libre utilización  Traslado  Insp. Calidad  \\\n",
      "23       714       0                0.0         1              0   \n",
      "24       714    1100                4.0         0              0   \n",
      "25       714       0                0.0         1              0   \n",
      "26       714    1600                0.0         0              0   \n",
      "34       714    1100              972.0         0              0   \n",
      "...      ...     ...                ...       ...            ...   \n",
      "15049    714    1600                0.0         0              0   \n",
      "15054    714       0                0.0         1              0   \n",
      "15055    714    1100                2.0         0              0   \n",
      "15063    714    1100                7.0         0              0   \n",
      "15064    714    1600                0.0         0              0   \n",
      "\n",
      "      Nro_pieza_fabricante_1 Material  \n",
      "23                       NaN   101104  \n",
      "24                       NaN   101104  \n",
      "25                       NaN   101132  \n",
      "26                       NaN   101132  \n",
      "34                       NaN   101796  \n",
      "...                      ...      ...  \n",
      "15049                1160147  1160147  \n",
      "15054                1161754  1161754  \n",
      "15055                1161754  1161754  \n",
      "15063                1161777  1161777  \n",
      "15064                1161777  1161777  \n",
      "\n",
      "[5226 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convierte 'Alm.' a entero, maneja NaN y luego convierte a cadena\n",
    "# dfleerstock['Alm.'] = pd.to_numeric(dfleerstock['Alm.'], errors='coerce').fillna(0).astype(int).astype(str)\n",
    "dfleerstock['Almacén'] = pd.to_numeric(dfleerstock['Almacén'], errors='coerce').fillna(0).astype(int).astype(str)\n",
    "\n",
    "# Convierte 'Ce.' a cadena\n",
    "dfleerstock['Centro'] = dfleerstock['Centro'].astype(str)\n",
    "# Convertir 'Ce.' a cadena y eliminar '.0'\n",
    "dfleerstock['Centro'] = dfleerstock['Centro'].astype(str).str.replace('.0', '', regex=False)\n",
    "\n",
    "\n",
    "# Define los valores permitidos para 'Alm.' y 'Ce.'\n",
    "# allowed_alm = ['1100', '1600']\n",
    "allowed_centers = ['710', '712', '713', '714', '0714', '0710', '0712', '0713']\n",
    "print(\"Valores únicos en Alm.:\", dfleerstock['Almacén'].unique())\n",
    "print(\"Valores únicos en Ce.:\", dfleerstock['Centro'].unique())\n",
    "\n",
    "df_filtered1 = dfleerstock[(dfleerstock['Centro'].isin(allowed_centers))].copy()\n",
    "\n",
    "# Convertir la columna 'Material' a tipo object (string) para evitar el .0\n",
    "\n",
    "df_filtered1.rename(columns={'Ult. Eslabon': 'Material'}, inplace=True)\n",
    "df_filtered1.head()\n",
    "FilteredUE = pd.merge(df_filtered1, df_cod_actual, left_on='Material', right_on='Nro_pieza_fabricante_1', how='left')\n",
    "\n",
    "# Rellenar los NaN en 'Cod_Actual_1' con los valores de 'Material' original\n",
    "FilteredUE['Cod_Actual_1'] = FilteredUE['Cod_Actual_1'].fillna(FilteredUE['Material'])\n",
    "# Eliminar la columna 'Material' y renombrar 'Cod_Actual_1' a 'Material'\n",
    "FilteredUE = FilteredUE.drop('Material', axis=1)\n",
    "\n",
    "\n",
    "# FilteredUE = FilteredUE.drop('Ult. Eslabon', axis=1)\n",
    "\n",
    "FilteredUE.rename(columns={'Inspecc.de calidad': 'Insp. Calidad', 'Trans./Trasl.': 'Traslado'}, inplace=True)\n",
    "\n",
    "FilteredUE.rename(columns={'Cod_Actual_1': 'Ult. Eslabon'}, inplace=True)\n",
    "# Aquí se ajustan los valores de 'Libre utilización' menores a 0 a 0\n",
    "FilteredUE['Libre utilización'] = FilteredUE['Libre utilización'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "# Verifica si hay algún registro después del filtrado\n",
    "if FilteredUE.empty:\n",
    "    print(\"No hay registros después del filtrado. Verifique los criterios de filtrado y los datos de entrada.\")\n",
    "else:\n",
    "    df_stock4 = FilteredUE.groupby(['Ult. Eslabon']).agg({\n",
    "        'Libre utilización': 'sum',\n",
    "        'Insp. Calidad': 'sum',\n",
    "        'Traslado': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    df_stock4['Ult. Eslabon'] = df_stock4['Ult. Eslabon'].astype(str)\n",
    "    df_stock4['Libre utilización'] = df_stock4['Libre utilización'].fillna(0).astype(int)\n",
    "    df_stock4['Traslado'] = df_stock4['Traslado'].fillna(0).astype(int)\n",
    "    df_stock4['Insp. Calidad'] = df_stock4['Insp. Calidad'].fillna(0).astype(int)\n",
    "\n",
    "    # Agregar una columna 'Control' sumando 'Insp. Calidad' y 'Traslado'\n",
    "    df_stock4['Control'] = df_stock4['Insp. Calidad'] + df_stock4['Traslado']\n",
    "    df_stock4.rename(columns={'Ult. Eslabon': 'Material'}, inplace=True)\n",
    "    FilteredUE = FilteredUE.rename(columns={'Ult. Eslabon': 'Material'})\n",
    "\n",
    "duplicados = df_stock4['Material'].duplicated()\n",
    "\n",
    "# Para ver si hay al menos un duplicado en esa columna\n",
    "hay_duplicados = duplicados.any()\n",
    "print(\"¿Hay duplicados?:\", hay_duplicados)\n",
    "\n",
    "# Para contar el número total de duplicados en esa columna\n",
    "numero_duplicados = duplicados.sum()\n",
    "print(\"Número de duplicados:\", numero_duplicados)\n",
    "\n",
    "\n",
    "df_duplicados = df_stock4[df_stock4['Material'].duplicated(keep=False)]\n",
    "print(df_duplicados)\n",
    "df_stock4 = df_stock4.drop_duplicates(keep='first')\n",
    "\n",
    "duplicados = FilteredUE['Material'].duplicated()\n",
    "\n",
    "# Para ver si hay al menos un duplicado en esa columna\n",
    "hay_duplicados = duplicados.any()\n",
    "print(\"¿Hay duplicados?:\", hay_duplicados)\n",
    "\n",
    "# Para contar el número total de duplicados en esa columna\n",
    "numero_duplicados = duplicados.sum()\n",
    "print(\"Número de duplicados:\", numero_duplicados)\n",
    "\n",
    "# Para obtener un DataFrame con todos los duplicados en esa columna\n",
    "df_duplicados = FilteredUE[FilteredUE['Material'].duplicated(keep=False)]\n",
    "print(df_duplicados)\n",
    "\n",
    "# STOCK 711\n",
    "# Especifica las columnas que necesitas\n",
    "cols_to_use4 = ['Material', 'Libre utilización', 'Almacén', 'Centro', 'Inspecc.de calidad', 'Trans./Trasl.', 'Ult. Eslabon']\n",
    "\n",
    "# Carga solo las columnas que necesitas desde la hoja \"Sheet1\"\n",
    "dfleerstock2 = pd.read_excel(ruta_destino_stock2, sheet_name='Sheet1', usecols=cols_to_use4)\n",
    "dfleerstock2.rename(columns={'Almacén': 'Alm.', 'Centro': 'Ce.', 'Inspecc.de calidad': 'Insp. Calidad', 'Trans./Trasl.': 'Traslado'}, inplace=True)\n",
    "dfleerstock.rename(columns={'Centro': 'Ce.'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convierte 'Alm.' y 'Ce.' a cadena para garantizar la consistencia en el filtrado\n",
    "dfleerstock2['Alm.'] = dfleerstock2['Alm.'].astype(str)\n",
    "dfleerstock2['Ce.'] = dfleerstock2['Ce.'].astype(str)\n",
    "dfleerstock['Ce.'] = dfleerstock['Ce.'].astype(str).str.replace('.0', '', regex=False)\n",
    "\n",
    "# Filtrar por 'Centro'\n",
    "allowed_centers2 = ['0711', '711', '711.0']\n",
    "df_filtered2 = dfleerstock2[dfleerstock2['Ce.'].isin(allowed_centers2)]\n",
    " # Convertir la columna 'Material' a tipo object (string) para evitar el .0\n",
    "FilteredUE711 = pd.merge(df_filtered2, df_cod_actual, left_on='Material', right_on='Nro_pieza_fabricante_1', how='left')\n",
    "FilteredUE711['Cod_Actual_1'] = FilteredUE711['Cod_Actual_1'].fillna(FilteredUE711['Material'])\n",
    "\n",
    "# Eliminar la columna 'Material' y renombrar 'Cod_Actual_1' a 'Material'\n",
    "FilteredUE711 = FilteredUE711.drop('Material', axis=1)\n",
    "FilteredUE711 = FilteredUE711.drop('Ult. Eslabon', axis=1)\n",
    "FilteredUE711.rename(columns={'Cod_Actual_1': 'Ult. Eslabon'}, inplace=True)\n",
    "\n",
    "# Verifica si hay algún registro después del filtrado\n",
    "if FilteredUE711.empty:\n",
    "    print(\"No hay registros después del filtrado. Verifique los criterios de filtrado y los datos de entrada.\")\n",
    "else:\n",
    "    # Agrupar por 'Material' y sumar las columnas especificadas\n",
    "    FilteredUE711 = FilteredUE711.groupby('Ult. Eslabon').agg({\n",
    "        'Libre utilización': 'sum',\n",
    "        'Insp. Calidad': 'sum',\n",
    "        'Traslado': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Convertir la columna 'Material' a tipo object (string) para evitar el .0\n",
    "    FilteredUE711['Ult. Eslabon'] = FilteredUE711['Ult. Eslabon'].astype(str)\n",
    "\n",
    "    # Añadir la columna 'Control' que es la suma de 'Insp. Calidad' y 'Traslado'\n",
    "    FilteredUE711['Control'] = FilteredUE711['Insp. Calidad'] + FilteredUE711['Traslado']\n",
    "\n",
    "    # Asumiendo que deseas rellenar los NaN con 0 y convertir a entero\n",
    "    FilteredUE711['Libre utilización'] = FilteredUE711['Libre utilización'].fillna(0).astype(int)\n",
    "    FilteredUE711['Insp. Calidad'] = FilteredUE711['Insp. Calidad'].fillna(0).astype(int)\n",
    "    FilteredUE711['Traslado'] = FilteredUE711['Traslado'].fillna(0).astype(int)\n",
    "    FilteredUE711['Control'] = FilteredUE711['Control'].fillna(0).astype(int)\n",
    "    FilteredUE711.rename(columns={'Ult. Eslabon': 'Material'}, inplace=True)\n",
    "\n",
    "    FilteredUE711.rename(columns={'Libre utilización': 'Stock 711'}, inplace=True)\n",
    "    #MERGE STOCK TIENDA ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#MERGE STOCK TIENDA ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "df_stock['Material'] = df_stock['Material'].astype(str)\n",
    "merged_df2 = pd.merge(merged_df2, df_stock[['Material', 'Stock Tiendas']], on='Material', how='left')\n",
    "merged_df2 = pd.merge(merged_df2, df_stock4[['Material', 'Libre utilización', 'Control']], on='Material', how='left')\n",
    "\n",
    "# Llenar NaN con 0 en la columna 'Libre utilización'\n",
    "merged_df2['Libre utilización'] = merged_df2['Libre utilización'].fillna(0)\n",
    "# Convertir 'Material' y 'Stock Tiendas' a enteros, asegurándose de que no haya NaNs\n",
    "merged_df2.rename(columns={'Libre utilización': 'Stock CD'}, inplace=True)\n",
    "merged_df2['Stock Tiendas'] = merged_df2['Stock Tiendas'].fillna(0)\n",
    "\n",
    "# Hacer un merge \n",
    "merged_df2 = pd.merge(merged_df2, FilteredUE711[['Material', 'Stock 711']], on='Material', how='left')\n",
    "\n",
    "merged_df2['Stock 711'] = merged_df2['Stock 711'].fillna(0)\n",
    "merged_df2['Control'] = merged_df2['Control'].fillna(0)\n",
    "merged_df2.head()\n",
    "\n",
    "\n",
    "# MANIPULAR FC ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Obtener los últimos dos dígitos del año actual y del siguiente año\n",
    "año_actual = datetime.now().year\n",
    "ultimo_digito_año_actual = str(año_actual)[-2:]\n",
    "ultimo_digito_año_siguiente = str(año_actual + 1)[-2:]\n",
    "\n",
    "# Leer el archivo Excel\n",
    "xlinbound = pd.ExcelFile(ruta_completa_archivo)\n",
    "\n",
    "# Buscar nombres de hojas que contengan la palabra 'Inbound' (en cualquier combinación de mayúsculas y minúsculas)\n",
    "hojas_inbound = [hoja for hoja in xlinbound.sheet_names if 'inbound' in hoja.lower()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Leer la hoja de Excel que contiene 'Inbound' en el nombre, empezando por la segunda fila\n",
    "if hojas_inbound:\n",
    "    # El parámetro 'header=1' indica que la segunda fila contiene los nombres de las columnas\n",
    "    inbound_dataframe = pd.read_excel(ruta_completa_archivo, sheet_name=hojas_inbound[0], header=1)\n",
    "    \n",
    "    # Filtrar columnas que contengan los últimos dos dígitos del año actual o del siguiente en el nombre\n",
    "    columnas_filtradas = [\n",
    "    col for col in inbound_dataframe.columns\n",
    "    if ultimo_digito_año_actual in str(col) or ultimo_digito_año_siguiente in str(col)\n",
    "]\n",
    "    inbound_dataframe_filtrado = inbound_dataframe[columnas_filtradas + ['Ult. Eslabón']]\n",
    "    \n",
    "    # Convertir las columnas pertinentes a strings para el merge\n",
    "    merged_df2['Material'] = merged_df2['Material'].astype(str)\n",
    "    inbound_dataframe_filtrado = inbound_dataframe_filtrado.copy()\n",
    "    inbound_dataframe_filtrado['Ult. Eslabón'] = inbound_dataframe_filtrado['Ult. Eslabón'].astype(str)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "month_to_number = {\n",
    "    'ene': 1, 'feb': 2, 'mar': 3, 'abr': 4, 'may': 5, 'jun': 6,\n",
    "    'jul': 7, 'ago': 8, 'sept': 9, 'oct': 10, 'nov': 11, 'dic': 12\n",
    "}\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Crear un nuevo DataFrame para los valores semanales\n",
    "weekly_values_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbound_dataframe_filtrado['Ult. Eslabón'] = inbound_dataframe_filtrado['Ult. Eslabón'].astype(str)\n",
    "inbound_dataframe_filtrado['Ult. Eslabón'] = inbound_dataframe_filtrado['Ult. Eslabón'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2024-04-01 00:00:00</th>\n",
       "      <th>2024-05-01 00:00:00</th>\n",
       "      <th>2024-06-01 00:00:00</th>\n",
       "      <th>2024-07-01 00:00:00</th>\n",
       "      <th>2024-08-01 00:00:00</th>\n",
       "      <th>2024-09-01 00:00:00</th>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <th>2024-11-01 00:00:00</th>\n",
       "      <th>2024-12-01 00:00:00</th>\n",
       "      <th>2025-01-01 00:00:00</th>\n",
       "      <th>2025-02-01 00:00:00</th>\n",
       "      <th>2025-03-01 00:00:00</th>\n",
       "      <th>Ult. Eslabón</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.163685</td>\n",
       "      <td>47.709373</td>\n",
       "      <td>47.34592</td>\n",
       "      <td>47.055160</td>\n",
       "      <td>46.822548</td>\n",
       "      <td>46.636463</td>\n",
       "      <td>46.48759</td>\n",
       "      <td>46.368496</td>\n",
       "      <td>46.273220</td>\n",
       "      <td>46.19700</td>\n",
       "      <td>46.136020</td>\n",
       "      <td>46.08724</td>\n",
       "      <td>1000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.138450</td>\n",
       "      <td>77.621956</td>\n",
       "      <td>76.40875</td>\n",
       "      <td>75.438194</td>\n",
       "      <td>74.661750</td>\n",
       "      <td>74.040596</td>\n",
       "      <td>73.54366</td>\n",
       "      <td>73.146126</td>\n",
       "      <td>72.828094</td>\n",
       "      <td>72.57367</td>\n",
       "      <td>72.370125</td>\n",
       "      <td>72.20729</td>\n",
       "      <td>1000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170.973830</td>\n",
       "      <td>170.336200</td>\n",
       "      <td>175.20654</td>\n",
       "      <td>175.206540</td>\n",
       "      <td>175.206540</td>\n",
       "      <td>175.206540</td>\n",
       "      <td>186.03125</td>\n",
       "      <td>186.031250</td>\n",
       "      <td>186.031250</td>\n",
       "      <td>175.20654</td>\n",
       "      <td>175.206540</td>\n",
       "      <td>175.20654</td>\n",
       "      <td>1000149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2024-04-01 00:00:00  2024-05-01 00:00:00  2024-06-01 00:00:00  \\\n",
       "0             0.000000             0.000000              0.00000   \n",
       "1             0.000000             0.000000              0.00000   \n",
       "2            48.163685            47.709373             47.34592   \n",
       "3            79.138450            77.621956             76.40875   \n",
       "4           170.973830           170.336200            175.20654   \n",
       "\n",
       "   2024-07-01 00:00:00  2024-08-01 00:00:00  2024-09-01 00:00:00  \\\n",
       "0             0.000000             0.000000             0.000000   \n",
       "1             0.000000             0.000000             0.000000   \n",
       "2            47.055160            46.822548            46.636463   \n",
       "3            75.438194            74.661750            74.040596   \n",
       "4           175.206540           175.206540           175.206540   \n",
       "\n",
       "   2024-10-01 00:00:00  2024-11-01 00:00:00  2024-12-01 00:00:00  \\\n",
       "0              0.00000             0.000000             0.000000   \n",
       "1              0.00000             0.000000             0.000000   \n",
       "2             46.48759            46.368496            46.273220   \n",
       "3             73.54366            73.146126            72.828094   \n",
       "4            186.03125           186.031250           186.031250   \n",
       "\n",
       "   2025-01-01 00:00:00  2025-02-01 00:00:00  2025-03-01 00:00:00 Ult. Eslabón  \n",
       "0              0.00000             0.000000              0.00000      1000078  \n",
       "1              0.00000             0.000000              0.00000      1000144  \n",
       "2             46.19700            46.136020             46.08724      1000147  \n",
       "3             72.57367            72.370125             72.20729      1000148  \n",
       "4            175.20654           175.206540            175.20654      1000149  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbound_dataframe_filtrado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter\n",
    "\n",
    "# Asumiendo que inbound_dataframe_filtrado es tu DataFrame original\n",
    "# Asegúrate de tener un diccionario para convertir el nombre del mes a número:\n",
    "month_to_number = {\"jan\": 1, \"feb\": 2, \"mar\": 3, \"apr\": 4, \"may\": 5, \"jun\": 6,\n",
    "                   \"jul\": 7, \"aug\": 8, \"sep\": 9, \"oct\": 10, \"nov\": 11, \"dec\": 12}\n",
    "\n",
    "# Inicializar el DataFrame de valores semanales\n",
    "weekly_values_df = pd.DataFrame()\n",
    "\n",
    "# Función para verificar si la columna es una fecha y convertirla a mes-año\n",
    "def convert_to_month_year(column_name):\n",
    "    try:\n",
    "        # Intenta convertir la columna a fecha\n",
    "        date = pd.to_datetime(column_name)\n",
    "        # Formatea la fecha a mes-año\n",
    "        return date.strftime('%m-%Y')\n",
    "    except ValueError:\n",
    "        # Si falla la conversión, asume que ya está en formato mes-año\n",
    "        return column_name\n",
    "\n",
    "for column in inbound_dataframe_filtrado.columns:\n",
    "    if column == 'Ult. Eslabón':\n",
    "        continue\n",
    "\n",
    "    column_name = convert_to_month_year(column)\n",
    "    mes, año = column_name.split('-')\n",
    "    mes_numero = int(mes)\n",
    "    año_numero = int(año)\n",
    "\n",
    "    valor_mensual = inbound_dataframe_filtrado[column].astype(float)\n",
    "    valor_semanal = valor_mensual / 4.33\n",
    "\n",
    "    primera_fecha = datetime(año_numero, mes_numero, 1)\n",
    "    ultima_fecha = primera_fecha + pd.offsets.MonthEnd()\n",
    "\n",
    "    dias_en_semana = Counter()\n",
    "    fecha_actual = primera_fecha\n",
    "    while fecha_actual <= ultima_fecha:\n",
    "        semana_del_año = fecha_actual.isocalendar()[1]\n",
    "        dias_en_semana[semana_del_año] += 1\n",
    "        fecha_actual += timedelta(days=1)\n",
    "\n",
    "    for semana, dias in dias_en_semana.items():\n",
    "        if dias >= 4:\n",
    "            # Ajustar el formato del nombre de columna a \"Sem X (YY)\"\n",
    "            nombre_columna_semana = f'Sem {semana} ({año_numero % 100:02d})'\n",
    "            weekly_values_df[nombre_columna_semana] = valor_semanal\n",
    "\n",
    "weekly_values_df['Ult. Eslabón'] = inbound_dataframe_filtrado['Ult. Eslabón'].values\n",
    "weekly_values_df.rename(columns={'Ult. Eslabón': 'Material'}, inplace=True)\n",
    "weekly_values_df.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sem 14 (24)</th>\n",
       "      <th>Sem 15 (24)</th>\n",
       "      <th>Sem 16 (24)</th>\n",
       "      <th>Sem 17 (24)</th>\n",
       "      <th>Sem 18 (24)</th>\n",
       "      <th>Sem 19 (24)</th>\n",
       "      <th>Sem 20 (24)</th>\n",
       "      <th>Sem 21 (24)</th>\n",
       "      <th>Sem 22 (24)</th>\n",
       "      <th>Sem 23 (24)</th>\n",
       "      <th>...</th>\n",
       "      <th>Sem 5 (25)</th>\n",
       "      <th>Sem 6 (25)</th>\n",
       "      <th>Sem 7 (25)</th>\n",
       "      <th>Sem 8 (25)</th>\n",
       "      <th>Sem 9 (25)</th>\n",
       "      <th>Sem 10 (25)</th>\n",
       "      <th>Sem 11 (25)</th>\n",
       "      <th>Sem 12 (25)</th>\n",
       "      <th>Sem 13 (25)</th>\n",
       "      <th>Material</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.123253</td>\n",
       "      <td>11.123253</td>\n",
       "      <td>11.123253</td>\n",
       "      <td>11.123253</td>\n",
       "      <td>11.018331</td>\n",
       "      <td>11.018331</td>\n",
       "      <td>11.018331</td>\n",
       "      <td>11.018331</td>\n",
       "      <td>11.018331</td>\n",
       "      <td>10.934393</td>\n",
       "      <td>...</td>\n",
       "      <td>10.669053</td>\n",
       "      <td>10.654970</td>\n",
       "      <td>10.654970</td>\n",
       "      <td>10.654970</td>\n",
       "      <td>10.654970</td>\n",
       "      <td>10.643704</td>\n",
       "      <td>10.643704</td>\n",
       "      <td>10.643704</td>\n",
       "      <td>10.643704</td>\n",
       "      <td>1000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.276778</td>\n",
       "      <td>18.276778</td>\n",
       "      <td>18.276778</td>\n",
       "      <td>18.276778</td>\n",
       "      <td>17.926549</td>\n",
       "      <td>17.926549</td>\n",
       "      <td>17.926549</td>\n",
       "      <td>17.926549</td>\n",
       "      <td>17.926549</td>\n",
       "      <td>17.646363</td>\n",
       "      <td>...</td>\n",
       "      <td>16.760663</td>\n",
       "      <td>16.713655</td>\n",
       "      <td>16.713655</td>\n",
       "      <td>16.713655</td>\n",
       "      <td>16.713655</td>\n",
       "      <td>16.676048</td>\n",
       "      <td>16.676048</td>\n",
       "      <td>16.676048</td>\n",
       "      <td>16.676048</td>\n",
       "      <td>1000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.485873</td>\n",
       "      <td>39.485873</td>\n",
       "      <td>39.485873</td>\n",
       "      <td>39.485873</td>\n",
       "      <td>39.338614</td>\n",
       "      <td>39.338614</td>\n",
       "      <td>39.338614</td>\n",
       "      <td>39.338614</td>\n",
       "      <td>39.338614</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>...</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>1000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29424</th>\n",
       "      <td>0.133914</td>\n",
       "      <td>0.133914</td>\n",
       "      <td>0.133914</td>\n",
       "      <td>0.133914</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>750797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29425</th>\n",
       "      <td>0.610726</td>\n",
       "      <td>0.610726</td>\n",
       "      <td>0.610726</td>\n",
       "      <td>0.610726</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>750803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29426</th>\n",
       "      <td>0.969977</td>\n",
       "      <td>0.969977</td>\n",
       "      <td>0.969977</td>\n",
       "      <td>0.969977</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>750809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29427</th>\n",
       "      <td>0.738339</td>\n",
       "      <td>0.738339</td>\n",
       "      <td>0.738339</td>\n",
       "      <td>0.738339</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>750816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29428</th>\n",
       "      <td>0.242494</td>\n",
       "      <td>0.242494</td>\n",
       "      <td>0.242494</td>\n",
       "      <td>0.242494</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>752466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29429 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sem 14 (24)  Sem 15 (24)  Sem 16 (24)  Sem 17 (24)  Sem 18 (24)  \\\n",
       "0         0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1         0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2        11.123253    11.123253    11.123253    11.123253    11.018331   \n",
       "3        18.276778    18.276778    18.276778    18.276778    17.926549   \n",
       "4        39.485873    39.485873    39.485873    39.485873    39.338614   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "29424     0.133914     0.133914     0.133914     0.133914     0.127537   \n",
       "29425     0.610726     0.610726     0.610726     0.610726     0.581644   \n",
       "29426     0.969977     0.969977     0.969977     0.969977     0.923788   \n",
       "29427     0.738339     0.738339     0.738339     0.738339     0.703180   \n",
       "29428     0.242494     0.242494     0.242494     0.242494     0.230947   \n",
       "\n",
       "       Sem 19 (24)  Sem 20 (24)  Sem 21 (24)  Sem 22 (24)  Sem 23 (24)  ...  \\\n",
       "0         0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "1         0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "2        11.018331    11.018331    11.018331    11.018331    10.934393  ...   \n",
       "3        17.926549    17.926549    17.926549    17.926549    17.646363  ...   \n",
       "4        39.338614    39.338614    39.338614    39.338614    40.463404  ...   \n",
       "...            ...          ...          ...          ...          ...  ...   \n",
       "29424     0.127537     0.127537     0.127537     0.127537     0.127537  ...   \n",
       "29425     0.581644     0.581644     0.581644     0.581644     0.581644  ...   \n",
       "29426     0.923788     0.923788     0.923788     0.923788     0.923788  ...   \n",
       "29427     0.703180     0.703180     0.703180     0.703180     0.703180  ...   \n",
       "29428     0.230947     0.230947     0.230947     0.230947     0.230947  ...   \n",
       "\n",
       "       Sem 5 (25)  Sem 6 (25)  Sem 7 (25)  Sem 8 (25)  Sem 9 (25)  \\\n",
       "0        0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1        0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2       10.669053   10.654970   10.654970   10.654970   10.654970   \n",
       "3       16.760663   16.713655   16.713655   16.713655   16.713655   \n",
       "4       40.463404   40.463404   40.463404   40.463404   40.463404   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "29424    0.127537    0.127537    0.127537    0.127537    0.127537   \n",
       "29425    0.581644    0.581644    0.581644    0.581644    0.581644   \n",
       "29426    0.923788    0.923788    0.923788    0.923788    0.923788   \n",
       "29427    0.703180    0.703180    0.703180    0.703180    0.703180   \n",
       "29428    0.230947    0.230947    0.230947    0.230947    0.230947   \n",
       "\n",
       "       Sem 10 (25)  Sem 11 (25)  Sem 12 (25)  Sem 13 (25)  Material  \n",
       "0         0.000000     0.000000     0.000000     0.000000   1000078  \n",
       "1         0.000000     0.000000     0.000000     0.000000   1000144  \n",
       "2        10.643704    10.643704    10.643704    10.643704   1000147  \n",
       "3        16.676048    16.676048    16.676048    16.676048   1000148  \n",
       "4        40.463404    40.463404    40.463404    40.463404   1000149  \n",
       "...            ...          ...          ...          ...       ...  \n",
       "29424     0.127537     0.127537     0.127537     0.127537    750797  \n",
       "29425     0.581644     0.581644     0.581644     0.581644    750803  \n",
       "29426     0.923788     0.923788     0.923788     0.923788    750809  \n",
       "29427     0.703180     0.703180     0.703180     0.703180    750816  \n",
       "29428     0.230947     0.230947     0.230947     0.230947    752466  \n",
       "\n",
       "[29429 rows x 53 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSITO ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Leer la hoja que se llama 'TR Final' en un DataFrame.\n",
    "try:\n",
    "    # Intenta cargar el archivo con el nombre de hoja 'Hoja1'\n",
    "    df_transito_original = pd.read_excel(ruta_destino_stock3, sheet_name='Sheet1', usecols='A:Q')\n",
    "except Exception as e:\n",
    "    # Si falla, imprime un mensaje de advertencia y carga el archivo con el nombre de hoja 'Sheet1'\n",
    "    print(f\"No se pudo cargar el archivo con el nombre de hoja 'Hoja1'. Error: {e}\")\n",
    "    try:\n",
    "        df_transito_original = pd.read_excel(ruta_destino_stock3, sheet_name='Sheet1')\n",
    "    except Exception as e:\n",
    "        # Si tampoco puede cargarlo con el nombre de hoja 'Sheet1', imprime un mensaje de error\n",
    "        print(f\"No se pudo cargar el archivo con el nombre de hoja 'Sheet1'. Error: {e}\")\n",
    "\n",
    "\n",
    "# Normalizar los nombres de las columnas (en caso de que haya inconsistencias en mayúsculas y minúsculas).\n",
    "# Normalizar los nombres de las columnas (en caso de que haya inconsistencias en mayúsculas y minúsculas).\n",
    "df_transito_original.columns = [col.title() if isinstance(col, str) else col for col in df_transito_original.columns]\n",
    "df_transito_original['Fecha'] = pd.to_datetime(df_transito_original['Fecha'])\n",
    "\n",
    "\n",
    "# Verificar que las columnas existan\n",
    "columnas_requeridas = ['Material', 'Cantidad', 'Fecha']\n",
    "for col in columnas_requeridas:\n",
    "    if col not in df_transito_original.columns:\n",
    "        raise ValueError(f\"La columna requerida '{col}' no está en el DataFrame.\")\n",
    "    \n",
    "    \n",
    "# Convertir todas las columnas a formato string (alfanumérico) excepto la columna de fecha\n",
    "for column in df_transito_original.columns:\n",
    "    if column != 'Fecha':  # Excluyendo la columna de fecha\n",
    "        df_transito_original[column] = df_transito_original[column].astype(str)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aux</th>\n",
       "      <th>Status</th>\n",
       "      <th>Material</th>\n",
       "      <th>Texto Breve</th>\n",
       "      <th>Cantidad</th>\n",
       "      <th>Centro</th>\n",
       "      <th>Nomsector_Actual</th>\n",
       "      <th>Origen</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Cl.Documento Compras</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Nombre De Proveedor</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Grupo De Compras</th>\n",
       "      <th>Semana</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Año</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>470002208440.0</td>\n",
       "      <td>No Facturado</td>\n",
       "      <td>1122554</td>\n",
       "      <td>CJ 2 UN DC FRE HIP FRE HF107</td>\n",
       "      <td>0</td>\n",
       "      <td>714</td>\n",
       "      <td>Repuesto Alternativo</td>\n",
       "      <td>NAC</td>\n",
       "      <td>AFM</td>\n",
       "      <td>ZSPT</td>\n",
       "      <td>2024-04-04</td>\n",
       "      <td>11599      Importadora Cuatro Rueda</td>\n",
       "      <td>nan</td>\n",
       "      <td>TT3</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>470002208450.0</td>\n",
       "      <td>No Facturado</td>\n",
       "      <td>1122564</td>\n",
       "      <td>CJ 2 UN DC FRE HIP FRE HF200B</td>\n",
       "      <td>0</td>\n",
       "      <td>714</td>\n",
       "      <td>Repuesto Alternativo</td>\n",
       "      <td>NAC</td>\n",
       "      <td>AFM</td>\n",
       "      <td>ZSPT</td>\n",
       "      <td>2024-04-04</td>\n",
       "      <td>11599      Importadora Cuatro Rueda</td>\n",
       "      <td>nan</td>\n",
       "      <td>TT3</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>470002208470.0</td>\n",
       "      <td>No Facturado</td>\n",
       "      <td>1122573</td>\n",
       "      <td>CJ 2 UN DC FRE HIP FRE HF21B</td>\n",
       "      <td>0</td>\n",
       "      <td>714</td>\n",
       "      <td>Repuesto Alternativo</td>\n",
       "      <td>NAC</td>\n",
       "      <td>AFM</td>\n",
       "      <td>ZSPT</td>\n",
       "      <td>2024-04-04</td>\n",
       "      <td>11599      Importadora Cuatro Rueda</td>\n",
       "      <td>nan</td>\n",
       "      <td>TT3</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>470002208480.0</td>\n",
       "      <td>No Facturado</td>\n",
       "      <td>1122591</td>\n",
       "      <td>CJ 2 UN DC FRE HIP FRE HF30</td>\n",
       "      <td>0</td>\n",
       "      <td>714</td>\n",
       "      <td>Repuesto Alternativo</td>\n",
       "      <td>NAC</td>\n",
       "      <td>AFM</td>\n",
       "      <td>ZSPT</td>\n",
       "      <td>2024-04-04</td>\n",
       "      <td>11599      Importadora Cuatro Rueda</td>\n",
       "      <td>nan</td>\n",
       "      <td>TT3</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4700022084100.0</td>\n",
       "      <td>No Facturado</td>\n",
       "      <td>1122605</td>\n",
       "      <td>CJ 2 UN DC FRE HIP FRE HF33</td>\n",
       "      <td>0</td>\n",
       "      <td>714</td>\n",
       "      <td>Repuesto Alternativo</td>\n",
       "      <td>NAC</td>\n",
       "      <td>AFM</td>\n",
       "      <td>ZSPT</td>\n",
       "      <td>2024-04-04</td>\n",
       "      <td>11599      Importadora Cuatro Rueda</td>\n",
       "      <td>nan</td>\n",
       "      <td>TT3</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36413</th>\n",
       "      <td>nan</td>\n",
       "      <td>Solped IMO Marzo</td>\n",
       "      <td>492770</td>\n",
       "      <td>RENOVADOR DE NEUMATICOS SONAX</td>\n",
       "      <td>30</td>\n",
       "      <td>714</td>\n",
       "      <td>Accesorios-Car Care</td>\n",
       "      <td>NAC</td>\n",
       "      <td>AFM</td>\n",
       "      <td>ZSTO</td>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>EMASA CHILE SPA</td>\n",
       "      <td>nan</td>\n",
       "      <td>TT3</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36414</th>\n",
       "      <td>nan</td>\n",
       "      <td>Solped IMO Marzo</td>\n",
       "      <td>492776</td>\n",
       "      <td>ESPUMA LIMPIA TAPICES SONAX</td>\n",
       "      <td>12</td>\n",
       "      <td>714</td>\n",
       "      <td>Accesorios-Car Care</td>\n",
       "      <td>NAC</td>\n",
       "      <td>AFM</td>\n",
       "      <td>ZSTO</td>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>EMASA CHILE SPA</td>\n",
       "      <td>nan</td>\n",
       "      <td>TT3</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36415</th>\n",
       "      <td>nan</td>\n",
       "      <td>Solped Compra NEU Directo TDA Marzo</td>\n",
       "      <td>1167588</td>\n",
       "      <td>225/55R18 ASSURANCE WEATH. 98V SL</td>\n",
       "      <td>37</td>\n",
       "      <td>714</td>\n",
       "      <td>Neumáticos</td>\n",
       "      <td>NAC</td>\n",
       "      <td>AFM</td>\n",
       "      <td>ZSTO</td>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>GOODYEAR DE CHILE SAIC</td>\n",
       "      <td>nan</td>\n",
       "      <td>TT3</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36416</th>\n",
       "      <td>nan</td>\n",
       "      <td>Solped Compra NEU Directo TDA Marzo</td>\n",
       "      <td>1167590</td>\n",
       "      <td>LT 245/70R17 WRANGLER AT ADV.</td>\n",
       "      <td>13</td>\n",
       "      <td>714</td>\n",
       "      <td>Neumáticos</td>\n",
       "      <td>NAC</td>\n",
       "      <td>AFM</td>\n",
       "      <td>ZSTO</td>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>GOODYEAR DE CHILE SAIC</td>\n",
       "      <td>nan</td>\n",
       "      <td>TT3</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36417</th>\n",
       "      <td>420000708910.0</td>\n",
       "      <td>Fecha Teórica</td>\n",
       "      <td>1020334</td>\n",
       "      <td>LUBRICANTE WD-40 CJ24UN 311GR</td>\n",
       "      <td>3096</td>\n",
       "      <td>714</td>\n",
       "      <td>Lubricantes</td>\n",
       "      <td>NAC</td>\n",
       "      <td>AFM</td>\n",
       "      <td>ZSTO</td>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>REPRESENTACIONES INDUSTRI</td>\n",
       "      <td>nan</td>\n",
       "      <td>TT3</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36418 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Aux                               Status Material  \\\n",
       "0       470002208440.0                         No Facturado  1122554   \n",
       "1       470002208450.0                         No Facturado  1122564   \n",
       "2       470002208470.0                         No Facturado  1122573   \n",
       "3       470002208480.0                         No Facturado  1122591   \n",
       "4      4700022084100.0                         No Facturado  1122605   \n",
       "...                ...                                  ...      ...   \n",
       "36413              nan                     Solped IMO Marzo   492770   \n",
       "36414              nan                     Solped IMO Marzo   492776   \n",
       "36415              nan  Solped Compra NEU Directo TDA Marzo  1167588   \n",
       "36416              nan  Solped Compra NEU Directo TDA Marzo  1167590   \n",
       "36417   420000708910.0                        Fecha Teórica  1020334   \n",
       "\n",
       "                             Texto Breve Cantidad Centro  \\\n",
       "0           CJ 2 UN DC FRE HIP FRE HF107        0    714   \n",
       "1          CJ 2 UN DC FRE HIP FRE HF200B        0    714   \n",
       "2           CJ 2 UN DC FRE HIP FRE HF21B        0    714   \n",
       "3            CJ 2 UN DC FRE HIP FRE HF30        0    714   \n",
       "4            CJ 2 UN DC FRE HIP FRE HF33        0    714   \n",
       "...                                  ...      ...    ...   \n",
       "36413      RENOVADOR DE NEUMATICOS SONAX       30    714   \n",
       "36414        ESPUMA LIMPIA TAPICES SONAX       12    714   \n",
       "36415  225/55R18 ASSURANCE WEATH. 98V SL       37    714   \n",
       "36416      LT 245/70R17 WRANGLER AT ADV.       13    714   \n",
       "36417      LUBRICANTE WD-40 CJ24UN 311GR     3096    714   \n",
       "\n",
       "           Nomsector_Actual Origen Tipo Cl.Documento Compras      Fecha  \\\n",
       "0      Repuesto Alternativo    NAC  AFM                 ZSPT 2024-04-04   \n",
       "1      Repuesto Alternativo    NAC  AFM                 ZSPT 2024-04-04   \n",
       "2      Repuesto Alternativo    NAC  AFM                 ZSPT 2024-04-04   \n",
       "3      Repuesto Alternativo    NAC  AFM                 ZSPT 2024-04-04   \n",
       "4      Repuesto Alternativo    NAC  AFM                 ZSPT 2024-04-04   \n",
       "...                     ...    ...  ...                  ...        ...   \n",
       "36413   Accesorios-Car Care    NAC  AFM                 ZSTO 2024-04-10   \n",
       "36414   Accesorios-Car Care    NAC  AFM                 ZSTO 2024-04-10   \n",
       "36415            Neumáticos    NAC  AFM                 ZSTO 2024-04-10   \n",
       "36416            Neumáticos    NAC  AFM                 ZSTO 2024-04-10   \n",
       "36417           Lubricantes    NAC  AFM                 ZSTO 2024-04-10   \n",
       "\n",
       "                       Nombre De Proveedor Unnamed: 12 Grupo De Compras  \\\n",
       "0      11599      Importadora Cuatro Rueda         nan              TT3   \n",
       "1      11599      Importadora Cuatro Rueda         nan              TT3   \n",
       "2      11599      Importadora Cuatro Rueda         nan              TT3   \n",
       "3      11599      Importadora Cuatro Rueda         nan              TT3   \n",
       "4      11599      Importadora Cuatro Rueda         nan              TT3   \n",
       "...                                    ...         ...              ...   \n",
       "36413                      EMASA CHILE SPA         nan              TT3   \n",
       "36414                      EMASA CHILE SPA         nan              TT3   \n",
       "36415               GOODYEAR DE CHILE SAIC         nan              TT3   \n",
       "36416               GOODYEAR DE CHILE SAIC         nan              TT3   \n",
       "36417            REPRESENTACIONES INDUSTRI         nan              TT3   \n",
       "\n",
       "      Semana Mes   Año  \n",
       "0         14   4  2024  \n",
       "1         14   4  2024  \n",
       "2         14   4  2024  \n",
       "3         14   4  2024  \n",
       "4         14   4  2024  \n",
       "...      ...  ..   ...  \n",
       "36413     15   4  2024  \n",
       "36414     15   4  2024  \n",
       "36415     15   4  2024  \n",
       "36416     15   4  2024  \n",
       "36417     15   4  2024  \n",
       "\n",
       "[36418 rows x 17 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transito_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna de fecha al formato correcto de fecha y hora\n",
    "df_transito_original['Fecha'] = pd.to_datetime(df_transito_original['Fecha'], errors='coerce')  # 'coerce' maneja los errores\n",
    "# Crear un nuevo DataFrame con 'Material' como índice y las combinaciones de 'Semanas' y 'Año' como columnas.\n",
    "# Primero'Semana_Año'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Aux', 'Status', 'Material', 'Texto Breve', 'Cantidad', 'Centro',\n",
       "       'Nomsector_Actual', 'Origen', 'Tipo', 'Cl.Documento Compras', 'Fecha',\n",
       "       'Nombre De Proveedor', 'Unnamed: 12', 'Grupo De Compras', 'Semana',\n",
       "       'Mes', 'Año'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transito_original.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PUEDE CAUSAR ERROR AL PONER SEMANA CORREGIR PONIENDO SEMANAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_transito_original['Semana_Año'] = df_transito_original.apply(lambda x: str(x['Semana']) + '-' + str(x['Año']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo 02.2024 S&OP Demanda Sin restricciones Inbound Ciclo Mar 24_Inbound.xlsx ha sido copiado a C:\\Users\\Etorres\\OneDrive - Inchcape\\Archivo Base Dispo\\Sem 12 exitosamente.\n",
      "Index(['Material', 'Sem 13 (24)', 'Sem 14 (24)'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Sem 13 (24)', 'Sem 14 (24)_y', 'Sem 14 (24)_x', 'Sem 15 (24)',\n",
       "       'Sem 16 (24)', 'Sem 17 (24)', 'Sem 18 (24)', 'Sem 19 (24)',\n",
       "       'Sem 20 (24)', 'Sem 21 (24)', 'Sem 22 (24)', 'Sem 23 (24)',\n",
       "       'Sem 24 (24)', 'Sem 25 (24)', 'Sem 26 (24)', 'Sem 27 (24)',\n",
       "       'Sem 28 (24)', 'Sem 29 (24)', 'Sem 30 (24)', 'Sem 31 (24)',\n",
       "       'Sem 32 (24)', 'Sem 33 (24)', 'Sem 34 (24)', 'Sem 35 (24)',\n",
       "       'Sem 36 (24)', 'Sem 37 (24)', 'Sem 38 (24)', 'Sem 39 (24)',\n",
       "       'Sem 40 (24)', 'Sem 41 (24)', 'Sem 42 (24)', 'Sem 43 (24)',\n",
       "       'Sem 44 (24)', 'Sem 45 (24)', 'Sem 46 (24)', 'Sem 47 (24)',\n",
       "       'Sem 48 (24)', 'Sem 49 (24)', 'Sem 50 (24)', 'Sem 51 (24)',\n",
       "       'Sem 52 (24)', 'Sem 1 (25)', 'Sem 2 (25)', 'Sem 3 (25)', 'Sem 4 (25)',\n",
       "       'Sem 5 (25)', 'Sem 6 (25)', 'Sem 7 (25)', 'Sem 8 (25)', 'Sem 9 (25)',\n",
       "       'Sem 10 (25)', 'Sem 11 (25)', 'Sem 12 (25)', 'Sem 13 (25)', 'Material'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función para obtener la semana correspondiente al mes de la fecha\n",
    "def asignar_semana_al_mes(fecha):\n",
    "    # Encuentra el primer día del mes de la fecha dada\n",
    "    primer_dia_del_mes = fecha.replace(day=1)\n",
    "    # Encuentra el último día de la semana en que cae el primer día del mes\n",
    "    ultimo_dia_semana = primer_dia_del_mes + timedelta(days=6 - primer_dia_del_mes.weekday())\n",
    "    # Si la fecha dada es mayor al último día de la primera semana completa del mes, usar la fecha dada\n",
    "    # De lo contrario, usa el primer día del mes\n",
    "    fecha_referencia = fecha if fecha > ultimo_dia_semana else primer_dia_del_mes\n",
    "    # Encuentra el año y la semana de la fecha de referencia\n",
    "    año, semana, dia_semana = fecha_referencia.isocalendar()\n",
    "    return semana, año\n",
    "\n",
    "# Aplicar la función a la columna 'Fecha' para obtener la nueva semana y año\n",
    "df_transito_original['Semana_Asignada'], df_transito_original['Año_Asignado'] = zip(*df_transito_original['Fecha'].apply(asignar_semana_al_mes))\n",
    "\n",
    "\n",
    "# Crear la columna 'Semana_Año_Asignada'\n",
    "df_transito_original['Semana_Año_Asignada'] = df_transito_original['Semana_Asignada'].astype(str) + '-' + df_transito_original['Año_Asignado'].astype(str)\n",
    "\n",
    "df_transito_original['Cantidad'] = pd.to_numeric(df_transito_original['Cantidad'], errors='coerce')\n",
    "\n",
    "df_transito = df_transito_original.pivot_table(\n",
    "    index='Material',\n",
    "    columns='Semana_Año_Asignada',\n",
    "    values='Cantidad',\n",
    "    aggfunc='sum',  # Sumará los valores numéricos\n",
    "    fill_value=0  # Llena con ceros si no hay valores\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# Renombrar las columnas para que sigan el formato 'Sem X (YY)'\n",
    "nuevos_nombres_columnas = {col: f\"Sem {int(col.split('-')[0])} ({col.split('-')[1][2:]})\" for col in df_transito.columns if '-' in col}\n",
    "df_transito.rename(columns=nuevos_nombres_columnas, inplace=True)\n",
    "inbound_dataframe_filtrado.rename(columns={'Ult. Eslabón': 'Material'}, inplace=True)\n",
    "\n",
    "df_transito['Material'] = df_transito['Material'].astype(str)\n",
    "\n",
    "# Ahora puedes realizar la conversión a string sin la advertencia\n",
    "inbound_dataframe_filtrado['Material'] = inbound_dataframe_filtrado['Material'].astype(str)\n",
    "\n",
    "#forecast anterior!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "import locale\n",
    "\n",
    "# Ruta donde se encuentran las carpetas por año y mes\n",
    "directorio_forecast_modificado = os.path.join(user_home_dir, 'Inchcape', 'Planificación y Compras Chile - Documentos', 'Planificación y Compras Aftermarket', 'Forecast Inbound')\n",
    "\n",
    "# Mapeo de nombres de meses en inglés a español\n",
    "meses_en_espanol_modificado = {\n",
    "    \"January\": \"Enero\",\n",
    "    \"February\": \"Febrero\",\n",
    "    \"March\": \"Marzo\",\n",
    "    \"April\": \"Abril\",\n",
    "    \"May\": \"Mayo\",\n",
    "    \"June\": \"Junio\",\n",
    "    \"July\": \"Julio\",\n",
    "    \"August\": \"Agosto\",\n",
    "    \"September\": \"Septiembre\",\n",
    "    \"October\": \"Octubre\",\n",
    "    \"November\": \"Noviembre\",\n",
    "    \"December\": \"Diciembre\"\n",
    "}\n",
    "\n",
    "# Establece el entorno local a inglés para obtener el mes en inglés\n",
    "locale.setlocale(locale.LC_TIME, 'en_US.UTF-8')\n",
    "\n",
    "# Función para obtener el nombre de la carpeta objetivo\n",
    "def obtener_nombre_carpeta_modificado(fecha):\n",
    "    año_modificado = fecha.strftime(\"%Y\")\n",
    "    mes_inglés_modificado = fecha.strftime(\"%B\")\n",
    "    mes_español_modificado = meses_en_espanol_modificado[mes_inglés_modificado]\n",
    "    mes_número_modificado = fecha.strftime(\"%m\")\n",
    "    return f\"{año_modificado}-{mes_número_modificado} {mes_español_modificado}\"\n",
    "\n",
    "# Calcular la fecha del mes anterior\n",
    "fecha_actual_modificado = datetime.now()\n",
    "fecha_mes_anterior_modificado = fecha_actual_modificado - timedelta(days=fecha_actual_modificado.day)\n",
    "nombre_carpeta_mes_anterior_modificado = obtener_nombre_carpeta_modificado(fecha_mes_anterior_modificado)\n",
    "\n",
    "# Buscar la carpeta del mes anterior\n",
    "ruta_carpeta_encontrada_modificado = \"\"\n",
    "for nombre_carpeta in os.listdir(directorio_forecast_modificado):\n",
    "    if nombre_carpeta_mes_anterior_modificado in nombre_carpeta:\n",
    "        ruta_carpeta_encontrada_modificado = os.path.join(directorio_forecast_modificado, nombre_carpeta)\n",
    "        break\n",
    "\n",
    "# Si se encontró la carpeta del mes anterior\n",
    "if ruta_carpeta_encontrada_modificado:\n",
    "    # Buscar el archivo con la palabra \"Inbound\" más reciente\n",
    "    lista_archivos_modificado = [archivo for archivo in os.listdir(ruta_carpeta_encontrada_modificado) if \"Inbound\" in archivo]\n",
    "    lista_archivos_modificado.sort(key=lambda archivo: os.path.getmtime(os.path.join(ruta_carpeta_encontrada_modificado, archivo)), reverse=True)\n",
    "    \n",
    "    if lista_archivos_modificado:\n",
    "        archivo_reciente_modificado = lista_archivos_modificado[0]\n",
    "        ruta_completa_archivo_modificado = os.path.join(ruta_carpeta_encontrada_modificado, archivo_reciente_modificado)\n",
    "        \n",
    "        # Copiar el archivo más reciente a la carpeta destino\n",
    "        carpeta_destino_semana_modificado = os.path.join(carpeta_destino_principal, f'Sem {semana_actual}')\n",
    "        shutil.copy(ruta_completa_archivo_modificado, carpeta_destino_semana_modificado)\n",
    "        print(f\"El archivo {archivo_reciente_modificado} ha sido copiado a {carpeta_destino_semana_modificado} exitosamente.\")\n",
    "    else:\n",
    "        print(f\"No se encontraron archivos con la palabra 'Inbound' en {ruta_carpeta_encontrada_modificado}.\")\n",
    "else:\n",
    "    print(f\"No se encontró la carpeta para el mes anterior.\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from datetime import timedelta\n",
    "\n",
    "# Continuación del código con nombres de variables modificados\n",
    "\n",
    "# Obtener los últimos dos dígitos del año actual y del siguiente año\n",
    "año_actual_modificado = datetime.now().year\n",
    "ultimo_digito_año_actual_modificado = str(año_actual_modificado)[-2:]\n",
    "ultimo_digito_año_siguiente_modificado = str(año_actual_modificado + 1)[-2:]\n",
    "\n",
    "# Leer el archivo Excel\n",
    "xlinbound_modificado = pd.ExcelFile(ruta_completa_archivo_modificado)\n",
    "\n",
    "# Buscar nombres de hojas que contengan la palabra 'Inbound'\n",
    "hojas_inbound_modificado = [hoja for hoja in xlinbound_modificado.sheet_names if 'inbound' in hoja.lower()]\n",
    "\n",
    "\n",
    "\n",
    "# Leer la hoja de Excel que contiene 'Inbound' en el nombre, empezando por la segunda fila\n",
    "if hojas_inbound_modificado:\n",
    "    inbound_dataframe_modificado = pd.read_excel(ruta_completa_archivo_modificado, sheet_name=hojas_inbound_modificado[0], header=1)\n",
    "    \n",
    "    # Filtrar columnas que contengan los últimos dos dígitos del año actual o del siguiente en el nombre\n",
    "    columnas_filtradas_modificado = [col for col in inbound_dataframe_modificado.columns if ultimo_digito_año_actual_modificado in col or ultimo_digito_año_siguiente_modificado in col]\n",
    "    inbound_dataframe_filtrado_modificado = inbound_dataframe_modificado[columnas_filtradas_modificado + ['Ult. Eslabón']]\n",
    "    # Usar .loc[] para realizar la modificación directamente en el DataFrame\n",
    "    inbound_dataframe_filtrado_modificado.loc[:, 'Ult. Eslabón'] = inbound_dataframe_filtrado_modificado['Ult. Eslabón'].astype(str)\n",
    " \n",
    "\n",
    "# Mapeo de meses a números\n",
    "month_to_number_modificado = {\n",
    "    'ene': 1, 'feb': 2, 'mar': 3, 'abr': 4, 'may': 5, 'jun': 6,\n",
    "    'jul': 7, 'ago': 8, 'sept': 9, 'oct': 10, 'nov': 11, 'dic': 12\n",
    "}\n",
    "\n",
    "# Crear un nuevo DataFrame para los valores semanales\n",
    "weekly_values_df_modificado = pd.DataFrame()\n",
    "\n",
    "for column in inbound_dataframe_filtrado_modificado.columns:\n",
    "    if column == 'Ult. Eslabón':\n",
    "        continue\n",
    "\n",
    "    mes_modificado, año_modificado = column.split('-')\n",
    "    mes_numero_modificado = month_to_number_modificado[mes_modificado.lower()]\n",
    "    año_numero_modificado = int('20' + año_modificado)\n",
    "\n",
    "    valor_mensual_modificado = inbound_dataframe_filtrado_modificado[column].astype(float)\n",
    "\n",
    "    # Dividir el valor mensual por el número aproximado de semanas\n",
    "    valor_semanal_modificado = valor_mensual_modificado / 4.33\n",
    "\n",
    "    # Determinar el rango de fechas de la semana para el mes\n",
    "    primera_fecha_modificada = datetime(año_numero_modificado, mes_numero_modificado, 1)\n",
    "    ultima_fecha_modificada = primera_fecha_modificada + pd.offsets.MonthEnd()\n",
    "\n",
    "    # Contar los días que pertenecen a cada mes\n",
    "    dias_en_semana_modificado = Counter()\n",
    "    fecha_actual_modificada = primera_fecha_modificada\n",
    "    while fecha_actual_modificada <= ultima_fecha_modificada:\n",
    "        semana_del_año_modificada = fecha_actual_modificada.isocalendar()[1]\n",
    "        dias_en_semana_modificado[semana_del_año_modificada] += 1\n",
    "        fecha_actual_modificada += timedelta(days=1)\n",
    "\n",
    "    # Asignar semanas a los meses correspondientes\n",
    "    for semana, dias in dias_en_semana_modificado.items():\n",
    "        if dias >= 4:  # Si al menos 4 días de la semana caen en este mes, asignar la semana a este mes\n",
    "            nombre_columna_semana_modificada = f'Sem {semana} ({año_modificado})'\n",
    "            weekly_values_df_modificado[nombre_columna_semana_modificada] = valor_semanal_modificado\n",
    "\n",
    "# Agregar la columna 'Ult. Eslabón' al nuevo DataFrame, asegurándote de que el índice coincida\n",
    "weekly_values_df_modificado['Ult. Eslabón'] = inbound_dataframe_filtrado_modificado['Ult. Eslabón'].values\n",
    "weekly_values_df_modificado.rename(columns={'Ult. Eslabón': 'Material'}, inplace=True)\n",
    "\n",
    "ruta_completa_archivo = os.path.join(carpeta_destino_semana, archivo_encontrado)\n",
    "UE = pd.read_excel(ruta_completa_archivo)\n",
    "UE.head()\n",
    "# Lista de columnas a eliminar\n",
    "\n",
    "\n",
    "# Ahora puedes eliminar las columnas\n",
    "columnas_a_eliminar = [\"Clave PIC\", \"Nº sec.\", \"Nro_pieza_fabricante\", \"Cod_actual\", \"Vál.desde\", \"Estado\"]\n",
    "UE = UE.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "# Realizar el merge\n",
    "merged_df = pd.merge(weekly_values_df_modificado, UE, \n",
    "                     left_on='Material', \n",
    "                     right_on='Nro_pieza_fabricante_1',\n",
    "                     how='left')\n",
    "\n",
    "# Reemplazar valores NaN en 'Cod_Actual_1' con los valores de 'Material'\n",
    "merged_df['Cod_Actual_1'] = merged_df['Cod_Actual_1'].fillna(merged_df['Material'])\n",
    "\n",
    "# Ahora, merged_df tiene 'Cod_Actual_1' con los valores de 'Material' donde no hubo coincidencias\n",
    "\n",
    "# Ahora puedes eliminar las columnas\n",
    "columnas_a_eliminar = [\"Nro_pieza_fabricante_1\", \"Material\"]\n",
    "merged_df = merged_df.drop(columns=columnas_a_eliminar)\n",
    "# Cambiar el nombre de la columna 'Cod_Actual_1' a 'Material'\n",
    "merged_df = merged_df.rename(columns={'Cod_Actual_1': 'Material'})\n",
    "merged_df.head()\n",
    "import calendar\n",
    "import datetime\n",
    "\n",
    "# Obtener el mes y año actual\n",
    "mes_actual23 = datetime.datetime.now().month\n",
    "año_actual23 = datetime.datetime.now().year\n",
    "\n",
    "# Obtener el número de semanas en el mes actual\n",
    "semanas_en_mes23 = calendar.monthcalendar(año_actual23, mes_actual23)\n",
    "\n",
    "# Determinar si el mes tiene 5 semanas o 4 semanas\n",
    "if len(semanas_en_mes23) == 5:\n",
    "    indice_columna = [3, 4]  # Si hay 5 semanas, considera las columnas 2 y 3\n",
    "else:\n",
    "    indice_columna = [3]  # Si hay 4 semanas, considera solo la columna 3\n",
    "\n",
    "# Construir la lista de columnas que comienzan con \"Sem\" y seleccionar las columnas según el índice determinado\n",
    "columnas_sem = [col for col in weekly_values_df_modificado.columns if col.startswith(\"Sem\")]\n",
    "cuarta_columna_sem = [columnas_sem[i] for i in indice_columna]\n",
    "# # Fusionar los DataFrames\n",
    "# Convertir las columnas seleccionadas en una lista de cadenas\n",
    "cuarta_columna_sem_str = [str(col) for col in cuarta_columna_sem]\n",
    "# _________\n",
    "\n",
    "# Seleccionar solo estas columnas en weekly_values_df_modificado\n",
    "columnas_a_conservar = [\"Material\"] + cuarta_columna_sem_str\n",
    "weekly_values_df_modificado = weekly_values_df_modificado[columnas_a_conservar]\n",
    "\n",
    "# Verificar las columnas seleccionadas\n",
    "print(weekly_values_df_modificado.columns)\n",
    "#_______________\n",
    "# Realiza el merge incluyendo la columna 'Material' de weekly_values_df_modificado\n",
    "weekly_values_df = pd.merge(weekly_values_df, weekly_values_df_modificado, \n",
    "                                           on='Material', \n",
    "                                           how='left')\n",
    "weekly_values_df.columns\n",
    "\n",
    "#______\n",
    "import calendar\n",
    "import datetime\n",
    "\n",
    "# Obtener el mes y año actual\n",
    "mes_actual32 = datetime.datetime.now().month\n",
    "año_actual32 = datetime.datetime.now().year\n",
    "\n",
    "# Obtener el número de semanas en el mes actual\n",
    "semanas_en_mes32 = calendar.monthcalendar(año_actual32, mes_actual32)\n",
    "\n",
    "# Determinar si el mes tiene 5 semanas o 4 semanas\n",
    "if len(semanas_en_mes32) == 5:\n",
    "    indice_ultima_semana = [-2,-1]\n",
    "else:\n",
    "    indice_ultima_semana = -1\n",
    "# Obtener la última columna del DataFrame con el índice ajustado\n",
    "# Obtener la última columna del DataFrame con los índices ajustados\n",
    "ultimas_columnas = [weekly_values_df.columns[indice] for indice in indice_ultima_semana]\n",
    "\n",
    "# Crear una nueva lista de nombres de columnas con las últimas columnas al principio\n",
    "nuevas_columnas = ultimas_columnas + [col for col in weekly_values_df.columns if col not in ultimas_columnas]\n",
    "ultimas_columnas\n",
    "\n",
    "\n",
    "# Reordenar las columnas del DataFrame\n",
    "weekly_values_df = weekly_values_df[nuevas_columnas]\n",
    "\n",
    "weekly_values_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sem 13 (24)</th>\n",
       "      <th>Sem 14 (24)_y</th>\n",
       "      <th>Sem 14 (24)_x</th>\n",
       "      <th>Sem 15 (24)</th>\n",
       "      <th>Sem 16 (24)</th>\n",
       "      <th>Sem 17 (24)</th>\n",
       "      <th>Sem 18 (24)</th>\n",
       "      <th>Sem 19 (24)</th>\n",
       "      <th>Sem 20 (24)</th>\n",
       "      <th>Sem 21 (24)</th>\n",
       "      <th>...</th>\n",
       "      <th>Sem 5 (25)</th>\n",
       "      <th>Sem 6 (25)</th>\n",
       "      <th>Sem 7 (25)</th>\n",
       "      <th>Sem 8 (25)</th>\n",
       "      <th>Sem 9 (25)</th>\n",
       "      <th>Sem 10 (25)</th>\n",
       "      <th>Sem 11 (25)</th>\n",
       "      <th>Sem 12 (25)</th>\n",
       "      <th>Sem 13 (25)</th>\n",
       "      <th>Material</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.588071</td>\n",
       "      <td>9.273704</td>\n",
       "      <td>11.123253</td>\n",
       "      <td>11.123253</td>\n",
       "      <td>11.123253</td>\n",
       "      <td>11.123253</td>\n",
       "      <td>11.018331</td>\n",
       "      <td>11.018331</td>\n",
       "      <td>11.018331</td>\n",
       "      <td>11.018331</td>\n",
       "      <td>...</td>\n",
       "      <td>10.669053</td>\n",
       "      <td>10.654970</td>\n",
       "      <td>10.654970</td>\n",
       "      <td>10.654970</td>\n",
       "      <td>10.654970</td>\n",
       "      <td>10.643704</td>\n",
       "      <td>10.643704</td>\n",
       "      <td>10.643704</td>\n",
       "      <td>10.643704</td>\n",
       "      <td>1000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.713626</td>\n",
       "      <td>27.713626</td>\n",
       "      <td>18.276778</td>\n",
       "      <td>18.276778</td>\n",
       "      <td>18.276778</td>\n",
       "      <td>18.276778</td>\n",
       "      <td>17.926549</td>\n",
       "      <td>17.926549</td>\n",
       "      <td>17.926549</td>\n",
       "      <td>17.926549</td>\n",
       "      <td>...</td>\n",
       "      <td>16.760663</td>\n",
       "      <td>16.713655</td>\n",
       "      <td>16.713655</td>\n",
       "      <td>16.713655</td>\n",
       "      <td>16.713655</td>\n",
       "      <td>16.676048</td>\n",
       "      <td>16.676048</td>\n",
       "      <td>16.676048</td>\n",
       "      <td>16.676048</td>\n",
       "      <td>1000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.463404</td>\n",
       "      <td>39.485873</td>\n",
       "      <td>39.485873</td>\n",
       "      <td>39.485873</td>\n",
       "      <td>39.485873</td>\n",
       "      <td>39.485873</td>\n",
       "      <td>39.338614</td>\n",
       "      <td>39.338614</td>\n",
       "      <td>39.338614</td>\n",
       "      <td>39.338614</td>\n",
       "      <td>...</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>40.463404</td>\n",
       "      <td>1000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29424</th>\n",
       "      <td>0.110727</td>\n",
       "      <td>0.110727</td>\n",
       "      <td>0.133914</td>\n",
       "      <td>0.133914</td>\n",
       "      <td>0.133914</td>\n",
       "      <td>0.133914</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>750797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29425</th>\n",
       "      <td>1.044445</td>\n",
       "      <td>1.044445</td>\n",
       "      <td>0.610726</td>\n",
       "      <td>0.610726</td>\n",
       "      <td>0.610726</td>\n",
       "      <td>0.610726</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>0.581644</td>\n",
       "      <td>750803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29426</th>\n",
       "      <td>0.933259</td>\n",
       "      <td>0.946472</td>\n",
       "      <td>0.969977</td>\n",
       "      <td>0.969977</td>\n",
       "      <td>0.969977</td>\n",
       "      <td>0.969977</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>750809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29427</th>\n",
       "      <td>0.740294</td>\n",
       "      <td>0.740294</td>\n",
       "      <td>0.738339</td>\n",
       "      <td>0.738339</td>\n",
       "      <td>0.738339</td>\n",
       "      <td>0.738339</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>750816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29428</th>\n",
       "      <td>0.692841</td>\n",
       "      <td>0.692841</td>\n",
       "      <td>0.242494</td>\n",
       "      <td>0.242494</td>\n",
       "      <td>0.242494</td>\n",
       "      <td>0.242494</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>752466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29429 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sem 13 (24)  Sem 14 (24)_y  Sem 14 (24)_x  Sem 15 (24)  Sem 16 (24)  \\\n",
       "0         0.000000       0.000000       0.000000     0.000000     0.000000   \n",
       "1         0.000000       0.000000       0.000000     0.000000     0.000000   \n",
       "2         9.588071       9.273704      11.123253    11.123253    11.123253   \n",
       "3        27.713626      27.713626      18.276778    18.276778    18.276778   \n",
       "4        40.463404      39.485873      39.485873    39.485873    39.485873   \n",
       "...            ...            ...            ...          ...          ...   \n",
       "29424     0.110727       0.110727       0.133914     0.133914     0.133914   \n",
       "29425     1.044445       1.044445       0.610726     0.610726     0.610726   \n",
       "29426     0.933259       0.946472       0.969977     0.969977     0.969977   \n",
       "29427     0.740294       0.740294       0.738339     0.738339     0.738339   \n",
       "29428     0.692841       0.692841       0.242494     0.242494     0.242494   \n",
       "\n",
       "       Sem 17 (24)  Sem 18 (24)  Sem 19 (24)  Sem 20 (24)  Sem 21 (24)  ...  \\\n",
       "0         0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "1         0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "2        11.123253    11.018331    11.018331    11.018331    11.018331  ...   \n",
       "3        18.276778    17.926549    17.926549    17.926549    17.926549  ...   \n",
       "4        39.485873    39.338614    39.338614    39.338614    39.338614  ...   \n",
       "...            ...          ...          ...          ...          ...  ...   \n",
       "29424     0.133914     0.127537     0.127537     0.127537     0.127537  ...   \n",
       "29425     0.610726     0.581644     0.581644     0.581644     0.581644  ...   \n",
       "29426     0.969977     0.923788     0.923788     0.923788     0.923788  ...   \n",
       "29427     0.738339     0.703180     0.703180     0.703180     0.703180  ...   \n",
       "29428     0.242494     0.230947     0.230947     0.230947     0.230947  ...   \n",
       "\n",
       "       Sem 5 (25)  Sem 6 (25)  Sem 7 (25)  Sem 8 (25)  Sem 9 (25)  \\\n",
       "0        0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1        0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2       10.669053   10.654970   10.654970   10.654970   10.654970   \n",
       "3       16.760663   16.713655   16.713655   16.713655   16.713655   \n",
       "4       40.463404   40.463404   40.463404   40.463404   40.463404   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "29424    0.127537    0.127537    0.127537    0.127537    0.127537   \n",
       "29425    0.581644    0.581644    0.581644    0.581644    0.581644   \n",
       "29426    0.923788    0.923788    0.923788    0.923788    0.923788   \n",
       "29427    0.703180    0.703180    0.703180    0.703180    0.703180   \n",
       "29428    0.230947    0.230947    0.230947    0.230947    0.230947   \n",
       "\n",
       "       Sem 10 (25)  Sem 11 (25)  Sem 12 (25)  Sem 13 (25)  Material  \n",
       "0         0.000000     0.000000     0.000000     0.000000   1000078  \n",
       "1         0.000000     0.000000     0.000000     0.000000   1000144  \n",
       "2        10.643704    10.643704    10.643704    10.643704   1000147  \n",
       "3        16.676048    16.676048    16.676048    16.676048   1000148  \n",
       "4        40.463404    40.463404    40.463404    40.463404   1000149  \n",
       "...            ...          ...          ...          ...       ...  \n",
       "29424     0.127537     0.127537     0.127537     0.127537    750797  \n",
       "29425     0.581644     0.581644     0.581644     0.581644    750803  \n",
       "29426     0.923788     0.923788     0.923788     0.923788    750809  \n",
       "29427     0.703180     0.703180     0.703180     0.703180    750816  \n",
       "29428     0.230947     0.230947     0.230947     0.230947    752466  \n",
       "\n",
       "[29429 rows x 55 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import calendar\n",
    "import datetime\n",
    "\n",
    "# Obtener el mes y año actual\n",
    "mes_actualxe = datetime.datetime.now().month\n",
    "año_actualxe = datetime.datetime.now().year\n",
    "\n",
    "# Obtener el número de semanas en el mes actual utilizando calendar.monthcalendar()\n",
    "# Esto retorna una lista de semanas, donde cada semana es una lista de días (0 si el día pertenece a otro mes)\n",
    "semanas_en_mesxe = calendar.monthcalendar(año_actual, mes_actual)\n",
    "\n",
    "# Determinar si estamos en la última semana del mes.\n",
    "# Para esto, comprobamos si la fecha actual está en la última semana que tiene días del mes actual.\n",
    "es_ultima_semana_del_mesxe = datetime.datetime.now().day in semanas_en_mesxe[-1]\n",
    "\n",
    "# Si estamos en la última semana del mes y el mes tiene 5 semanas (determinado por la longitud de semanas_en_mes),\n",
    "# entonces eliminamos la primera columna del DataFrame.\n",
    "if es_ultima_semana_del_mesxe and len(semanas_en_mesxe) == 5:\n",
    "    weekly_values_df = weekly_values_df.iloc[:, 1:]\n",
    "\n",
    "weekly_values_df.fillna(0, inplace=True)\n",
    "weekly_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sem 13 (24)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "# Obtener la fecha actual\n",
    "fecha_actual = datetime.datetime.now()\n",
    "# Establecer la fecha de referencia en el día 15 del mes actual\n",
    "fecha_referencia = fecha_actual.replace(day=25)\n",
    "\n",
    "# Encontrar el número de semana del año para el día 15 del mes\n",
    "numero_semana_quincena = fecha_referencia.isocalendar()[1]\n",
    "\n",
    "nombre_columna_semana = f\"Sem {numero_semana_quincena} ({fecha_actual.strftime('%y')})\"\n",
    "\n",
    "merged_df2[nombre_columna_semana] = np.nan  # Agregar la nueva columna con el nombre de la semana calculada\n",
    "# todo numerico\n",
    "merged_df2['Stock Tiendas'] = pd.to_numeric(merged_df2['Stock Tiendas'], errors='coerce').fillna(0)\n",
    "merged_df2['Stock CD'] = pd.to_numeric(merged_df2['Stock CD'], errors='coerce').fillna(0)\n",
    "merged_df2['Faltante AP'] = pd.to_numeric(merged_df2['Faltante AP'], errors='coerce').fillna(0)\n",
    "merged_df2['Faltantes'] = pd.to_numeric(merged_df2['Faltantes'], errors='coerce').fillna(0)\n",
    "\n",
    "# Realizar el cálculo y asignarlo a la nueva columna\n",
    "merged_df2[nombre_columna_semana] = (merged_df2['Stock Tiendas'] + merged_df2['Stock CD']) - (merged_df2['Faltantes'])\n",
    "print(nombre_columna_semana)\n",
    "\n",
    "merged_df2['Material'] = merged_df2['Material'].astype(str)\n",
    "df_transito['Material'] = df_transito['Material'].astype(str)\n",
    "weekly_values_df['Material'] = weekly_values_df['Material'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semana_actual =numero_semana_quincena\n",
    "semana_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sem 13 (24)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NotImplementedType' object has no attribute '_indexed_same'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23312\\3026168175.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Material'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_transito_nueva'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m \u001b[0mmerged_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnombre_columna_semana_nueva\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmerged_df2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnombre_columna_semana_nueva\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_transito_nueva'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;31m# Merge con el forecast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m merged_df2 = merged_df2.merge(\n",
      "\u001b[1;32mc:\\Users\\Etorres\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m  12268\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12269\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12270\u001b[0m         \u001b[1;31m# error: Unsupported left operand type for + (\"Type[NDFrame]\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 12271\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inplace_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__add__\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[operator]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Etorres\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m  12245\u001b[0m         \u001b[0mWrap\u001b[0m \u001b[0marithmetic\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mto\u001b[0m \u001b[0moperate\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12246\u001b[0m         \"\"\"\n\u001b[0;32m  12247\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 12249\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indexed_same\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  12250\u001b[0m             \u001b[1;31m# GH#36498 this inplace op can _actually_ be inplace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12251\u001b[0m             \u001b[1;31m# Item \"ArrayManager\" of \"Union[ArrayManager, SingleArrayManager,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  12252\u001b[0m             \u001b[1;31m# BlockManager, SingleBlockManager]\" has no attribute \"setitem_inplace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NotImplementedType' object has no attribute '_indexed_same'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# fecha_referencia = datetime.now().replace(day=1)\n",
    "# numero_semana_quincena = fecha_referencia.isocalendar()[1]\n",
    "\n",
    "# Calcular la semana siguiente y ajustar el año si es necesario\n",
    "semana_siguiente = semana_actual + 1\n",
    "año_actual = fecha_referencia.year\n",
    "\n",
    "if semana_siguiente > 52:\n",
    "    semana_siguiente = 1\n",
    "    año_actual += 1\n",
    "\n",
    "# Crear el nombre de la columna para la semana siguiente\n",
    "nombre_columna_semana_siguiente = f\"Sem {semana_siguiente} ({str(año_actual)[-2:]})\"\n",
    "\n",
    "# Inicializar la columna de la semana siguiente en merged_df4\n",
    "merged_df2[nombre_columna_semana_siguiente] = merged_df2[nombre_columna_semana]\n",
    "\n",
    "if nombre_columna_semana in merged_df2.columns:\n",
    "    merged_df2[nombre_columna_semana_siguiente] = pd.to_numeric(merged_df2[nombre_columna_semana], errors='coerce').fillna(0)\n",
    "\n",
    "# Asegurarse de que la columna 'Control' es numérica\n",
    "merged_df2['Control'] = pd.to_numeric(merged_df2['Control'], errors='coerce').fillna(0)\n",
    "\n",
    "# Sumar los valores de la columna 'Control' a la nueva columna de la semana siguiente\n",
    "merged_df2[nombre_columna_semana_siguiente] += merged_df2['Control']\n",
    "\n",
    "merged_df2['Material'] = merged_df2['Material'].astype(str)\n",
    "df_transito['Material'] = df_transito['Material'].astype(str)\n",
    "weekly_values_df['Material'] = weekly_values_df['Material'].astype(str)\n",
    "\n",
    "merged_df2 = merged_df2.merge(df_transito[['Material', nombre_columna_semana_siguiente]], on='Material', how='left', suffixes=('', '_transito'))\n",
    "merged_df2[nombre_columna_semana_siguiente] = merged_df2[nombre_columna_semana_siguiente] + merged_df2[nombre_columna_semana_siguiente + '_transito'].fillna(0)\n",
    "\n",
    "# Combinación (merge) con weekly_values_df\n",
    "merged_df2 = merged_df2.merge(weekly_values_df[['Material', nombre_columna_semana_siguiente]], on='Material', how='left', suffixes=('', '_weekly'))\n",
    "\n",
    "# Condición para realizar la resta solo si el valor después de sumar con transito es mayor a 0\n",
    "merged_df2[nombre_columna_semana_siguiente] = merged_df2.apply(\n",
    "    lambda row: row[nombre_columna_semana_siguiente] - row[nombre_columna_semana_siguiente + '_weekly']\n",
    "    if row[nombre_columna_semana_siguiente] > 0 else row[nombre_columna_semana_siguiente], axis=1\n",
    ").fillna(0)\n",
    "\n",
    "# Eliminar las columnas auxiliares del merge\n",
    "merged_df2.drop(columns=[nombre_columna_semana_siguiente + '_transito', nombre_columna_semana_siguiente + '_weekly'], inplace=True)\n",
    "\n",
    "# Imprimir el DataFrame para verificar los resultados\n",
    "print(nombre_columna_semana_siguiente)\n",
    "\n",
    "#TERCERA SEMANA ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# Convierte todo a strng\n",
    "merged_df2['Material'] = merged_df2['Material'].astype(str)\n",
    "df_transito['Material'] = df_transito['Material'].astype(str)\n",
    "weekly_values_df['Material'] = weekly_values_df['Material'].astype(str)\n",
    "\n",
    "semana_actual = int(nombre_columna_semana_siguiente.split(' ')[1].split('(')[0])\n",
    "año_actual = int(nombre_columna_semana_siguiente.split('(')[1].split(')')[0])\n",
    "semana_nueva = semana_actual + 1\n",
    "año_nuevo = año_actual\n",
    "if semana_nueva > 52:\n",
    "    semana_nueva = 1\n",
    "    año_nuevo += 1\n",
    "nombre_columna_semana_nueva = f\"Sem {semana_nueva} ({str(año_nuevo)[-2:]})\"\n",
    "\n",
    "# Inicializa la columna de la nueva semana en merged_df4.\n",
    "merged_df2[nombre_columna_semana_nueva] = merged_df2[nombre_columna_semana_siguiente]\n",
    "\n",
    "# Asegúrate de que la columna 'Stock 711' es numérica.\n",
    "merged_df2['Stock 711'] = pd.to_numeric(merged_df2['Stock 711'], errors='coerce').fillna(0)\n",
    "\n",
    "# Suma los valores de la columna 'Stock 711' a la nueva columna de la semana.\n",
    "merged_df2[nombre_columna_semana_nueva] += merged_df2['Stock 711']\n",
    "\n",
    "# Realiza el merge con 'df_transito' y suma los valores correspondientes a la nueva semana.\n",
    "merged_df2 = merged_df2.merge(\n",
    "    df_transito[['Material', nombre_columna_semana_nueva]],\n",
    "    on='Material',\n",
    "    how='left',\n",
    "    suffixes=('', '_transito_nueva')\n",
    ")\n",
    "merged_df2[nombre_columna_semana_nueva] += merged_df2[nombre_columna_semana_nueva + '_transito_nueva'].fillna(0)\n",
    "\n",
    "# Merge con el forecast\n",
    "merged_df2 = merged_df2.merge(\n",
    "    weekly_values_df[['Material', nombre_columna_semana_nueva]],\n",
    "    on='Material',\n",
    "    how='left',\n",
    "    suffixes=('', '_forecast_nueva')\n",
    ")\n",
    "\n",
    "## Restar solo si el resultado del merge con 'df_transito' es igual o mayor a 0\n",
    "merged_df2[nombre_columna_semana_nueva] = merged_df2.apply(\n",
    "    lambda row: row[nombre_columna_semana_nueva] - row[nombre_columna_semana_nueva + '_forecast_nueva']\n",
    "    if row[nombre_columna_semana_nueva] > 0 else row[nombre_columna_semana_nueva], axis=1\n",
    ").fillna(0)\n",
    "\n",
    "# Eliminar las columnas auxiliares del merge\n",
    "merged_df2.drop(columns=[nombre_columna_semana_nueva + '_transito_nueva', nombre_columna_semana_nueva + '_forecast_nueva'], inplace=True)\n",
    "print(nombre_columna_semana_nueva)\n",
    "\n",
    "#sers\\Etorres\\Desktop\\FC6.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#46 SEMANAS ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "\n",
    "semana_actual = int(nombre_columna_semana_siguiente.split(' ')[1].split('(')[0])\n",
    "año_actual = int(nombre_columna_semana_siguiente.split('(')[1].split(')')[0])\n",
    "semana_siguiente = semana_actual + 1\n",
    "año_siguiente = año_actual\n",
    "if semana_siguiente > 52:\n",
    "    semana_siguiente = 1\n",
    "    año_siguiente += 1\n",
    "nombre_columna_semana_siguiente = f\"Sem {semana_siguiente} ({str(año_siguiente)[-2:]})\"\n",
    "\n",
    "for i in range(43):  # Repetir el proceso 46 veces\n",
    "    # Calcula el nombre de la columna de la nueva semana.\n",
    "    semana_actual = int(nombre_columna_semana_siguiente.split(' ')[1].split('(')[0])\n",
    "    año_actual = int(nombre_columna_semana_siguiente.split('(')[1].split(')')[0])\n",
    "    semana_nueva = semana_actual + 1\n",
    "    año_nuevo = año_actual\n",
    "    if semana_nueva > 52:\n",
    "        semana_nueva = 1\n",
    "        año_nuevo += 1\n",
    "    nombre_columna_semana_nueva = f\"Sem {semana_nueva} ({str(año_nuevo)[-2:]})\"\n",
    "\n",
    "    # Inicializa la columna de la nueva semana en merged_df4.\n",
    "    merged_df2[nombre_columna_semana_nueva] = merged_df2[nombre_columna_semana_siguiente]\n",
    "\n",
    "    # Realiza el merge con 'df_transito' y suma los valores correspondientes a la nueva semana.\n",
    "    if nombre_columna_semana_nueva in df_transito.columns:\n",
    "        merged_df2 = merged_df2.merge(\n",
    "            df_transito[['Material', nombre_columna_semana_nueva]],\n",
    "            on='Material',\n",
    "            how='left',\n",
    "            suffixes=('', '_transito_nueva')\n",
    "        )\n",
    "        merged_df2[nombre_columna_semana_nueva] += merged_df2[nombre_columna_semana_nueva + '_transito_nueva'].fillna(0)\n",
    "        # Elimina la columna auxiliar del merge\n",
    "        merged_df2.drop(columns=[nombre_columna_semana_nueva + '_transito_nueva'], inplace=True)\n",
    "\n",
    "        # Realiza el merge con 'weekly_values_df' y resta el forecast correspondiente a la nueva semana solo si el total es mayor a 0\n",
    "        if nombre_columna_semana_nueva in weekly_values_df.columns:\n",
    "            merged_df2 = merged_df2.merge(\n",
    "                weekly_values_df[['Material', nombre_columna_semana_nueva]],\n",
    "                on='Material',\n",
    "                how='left',\n",
    "                suffixes=('', '_forecast_nueva')\n",
    "            )\n",
    "            merged_df2[nombre_columna_semana_nueva] = merged_df2.apply(\n",
    "                lambda row: max(row[nombre_columna_semana_nueva] - row[nombre_columna_semana_nueva + '_forecast_nueva'], 0)\n",
    "                if row[nombre_columna_semana_nueva] > 0 else row[nombre_columna_semana_nueva], axis=1\n",
    "            ).fillna(0)\n",
    "            merged_df2.drop(columns=[nombre_columna_semana_nueva + '_forecast_nueva'], inplace=True)\n",
    "\n",
    "    # Actualiza el nombre de la columna para la próxima iteración\n",
    "    nombre_columna_semana_siguiente = nombre_columna_semana_nueva\n",
    "\n",
    "#PORCENTAJES DE DISPONIBILIDAD\n",
    "\n",
    "columnas_semanas = [col for col in merged_df2.columns if col.startswith(\"Sem \") and \"D\" not in col]\n",
    "\n",
    "# Realizar un merge (fusión) para alinear las filas según el 'Material'\n",
    "merged_df2 = merged_df2.merge(weekly_values_df[['Material'] + columnas_semanas], on='Material', how='left', suffixes=('', '_weekly'))\n",
    "\n",
    "# Diccionario para almacenar las nuevas columnas\n",
    "nuevas_columnas = {}\n",
    "\n",
    "# Iterar sobre las columnas de semanas originales\n",
    "for col in columnas_semanas:\n",
    "    nueva_col = col + \"D\"  # Crear el nombre de la nueva columna añadiendo \"D\" al final\n",
    "\n",
    "    # Realizar el cálculo basado en las condiciones\n",
    "    condiciones = [\n",
    "        merged_df2[col] < 0,\n",
    "        (merged_df2[col] == 0) & (merged_df2[col + '_weekly'] > 0),\n",
    "        (merged_df2[col] == 0) & (merged_df2[col + '_weekly'] == 0),\n",
    "        (merged_df2[col] > 0) & (merged_df2[col + '_weekly'] == 0),\n",
    "        (merged_df2[col] > 0) & (merged_df2[col + '_weekly'] > 0),\n",
    "        (merged_df2[col] >= 0) & (merged_df2[col + '_weekly'].isnull() | (merged_df2[col + '_weekly'] == 0))\n",
    "    ]\n",
    "\n",
    "    # Resultados basados en las condiciones\n",
    "    resultados = [\n",
    "        0,  # Semana < 0\n",
    "        0,  # Semana = 0 y weekly > 0\n",
    "        100,  # Semana = 0 y weekly = 0\n",
    "        100,  # Semana > 0 y weekly = 0\n",
    "        merged_df2[col] / merged_df2[col + '_weekly'] * 100,  # Semana > 0 y weekly > 0\n",
    "        100  # Semana >= 0 y no hay weekly o weekly = 0\n",
    "    ]\n",
    "\n",
    "    # Aplicar las condiciones y almacenar en el diccionario\n",
    "    columna_temporal = pd.Series(0, index=merged_df2.index).astype(float)  # Inicializar con 0\n",
    "    for cond, res in zip(condiciones, resultados):\n",
    "        columna_temporal[cond] = res.clip(upper=100) if not isinstance(res, int) else res\n",
    "    \n",
    "    nuevas_columnas[nueva_col] = columna_temporal\n",
    "\n",
    "# Concatenar todas las nuevas columnas a merged_df2\n",
    "merged_df2 = pd.concat([merged_df2, pd.DataFrame(nuevas_columnas)], axis=1)\n",
    "# Eliminar las columnas que terminan en \"_weekly\"\n",
    "columnas_weekly = [col for col in merged_df2.columns if col.endswith('_weekly')]\n",
    "merged_df2.drop(columns=columnas_weekly, inplace=True)\n",
    "merged_df2.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop_dir = os.path.join(os.path.expanduser('~'), 'OneDrive - Inchcape', 'Escritorio')\n",
    "merged_df2.to_excel(os.path.join(desktop_dir, 'DispoFutura.xlsx'), index=False)\n",
    "df_transito.to_excel(os.path.join(desktop_dir, 'TR_Semanal.xlsx'), index=False)\n",
    "weekly_values_df.to_excel(os.path.join(desktop_dir, 'FC_Semanal.xlsx'), index=False)\n",
    "weekly_values_df_modificado.to_excel(os.path.join(desktop_dir, 'FC_Semanal2.xlsx'), index=False)\n",
    "df_stock.to_excel(os.path.join(desktop_dir, 'Stock_Tiendas.xlsx'), index=False)\n",
    "df_stock4.to_excel(os.path.join(desktop_dir, 'Stock_CD.xlsx'), index=False)\n",
    "FilteredUE711.to_excel(os.path.join(desktop_dir, 'Stock_711.xlsx'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
